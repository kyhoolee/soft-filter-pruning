{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'caffe_cifar',\n",
       " 'preresnet110',\n",
       " 'preresnet20',\n",
       " 'preresnet32',\n",
       " 'preresnet44',\n",
       " 'preresnet56',\n",
       " 'resnet101',\n",
       " 'resnet101_small',\n",
       " 'resnet110',\n",
       " 'resnet152',\n",
       " 'resnet152_small',\n",
       " 'resnet18',\n",
       " 'resnet18_small',\n",
       " 'resnet20',\n",
       " 'resnet32',\n",
       " 'resnet34',\n",
       " 'resnet34_small',\n",
       " 'resnet44',\n",
       " 'resnet50',\n",
       " 'resnet50_small',\n",
       " 'resnet56',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models\n",
    "from utils import convert_secs2time, time_string, time_file_str\n",
    "# from models import print_log\n",
    "import models\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DotMap(data='/home/hongky/datasets/imagenet', save_dir='0310_resnet101/resnet101-rate-0.7/', arch='resnet101', workers=8, epochs=10, start_epoch=0, batch_size=256, lr=0.1, momentum=0.9, weight_decay=0.0001, print_freq=200, resume='', evaluate=False, use_pretrain=True, rate=0.7, layer_begin=0, layer_end=309, layer_inter=3, epoch_prune=1, skip_downsample=1, use_sparse=False, sparse='', lr_adjust=30, use_cuda=True, prefix='2020-10-03-416')\n"
     ]
    }
   ],
   "source": [
    "from dotmap import DotMap\n",
    "\n",
    "args = DotMap()\n",
    "\n",
    "args.data = '/home/hongky/datasets/imagenet'\n",
    "args.save_dir = '0310_resnet101/resnet101-rate-0.7/'\n",
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir)\n",
    "    \n",
    "args.arch = 'resnet101'\n",
    "args.workers = 8\n",
    "args.epochs = 10\n",
    "args.start_epoch = 0\n",
    "args.batch_size = 256\n",
    "args.lr = 0.1\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 1e-4\n",
    "args.print_freq = 200\n",
    "args.resume=''\n",
    "\n",
    "args.evaluate = False \n",
    "args.use_pretrain = True\n",
    "\n",
    "# python pruning_train.py \n",
    "# -a resnet101 \n",
    "# --save_dir ./snapshots/resnet101-rate-0.7 \n",
    "# --rate 0.7 \n",
    "# --layer_begin 0 \n",
    "# --layer_end 309 \n",
    "# --layer_inter 3  \n",
    "# /path/to/Imagenet2012\n",
    "\n",
    "# compress-rate\n",
    "args.rate = 0.7\n",
    "args.layer_begin = 0\n",
    "args.layer_end = 309\n",
    "args.layer_inter = 3\n",
    "\n",
    "args.epoch_prune=1\n",
    "args.skip_downsample=1\n",
    "args.use_sparse=False \n",
    "args.sparse=''\n",
    "args.lr_adjust=30\n",
    "\n",
    "\n",
    "args.use_cuda = torch.cuda.is_available()\n",
    "args.prefix = time_file_str()\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_sparse(model):\n",
    "    checkpoint = torch.load(args.sparse)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint['state_dict'].items():\n",
    "        name = k[7:]  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print(\"sparse_model_loaded\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, log):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print_log('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses, top1=top1, top5=top5), log)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, log):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print_log('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                top1=top1, top5=top5), log)\n",
    "\n",
    "    print_log(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}'.format(top1=top1, top5=top5,\n",
    "                                                                                           error1=100 - top1.avg), log)\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename, bestname):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, bestname)\n",
    "\n",
    "\n",
    "def print_log(print_string, log):\n",
    "    print(\"{:}\".format(print_string))\n",
    "    log.write('{:}\\n'.format(print_string))\n",
    "    log.flush()\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // args.lr_adjust))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class Mask:\n",
    "    def __init__(self, model):\n",
    "        self.model_size = {}\n",
    "        self.model_length = {}\n",
    "        self.compress_rate = {}\n",
    "        self.mat = {}\n",
    "        self.model = model\n",
    "        self.mask_index = []\n",
    "\n",
    "    def get_codebook(self, weight_torch, compress_rate, length):\n",
    "        weight_vec = weight_torch.view(length)\n",
    "        weight_np = weight_vec.cpu().numpy()\n",
    "\n",
    "        weight_abs = np.abs(weight_np)\n",
    "        weight_sort = np.sort(weight_abs)\n",
    "\n",
    "        threshold = weight_sort[int(length * (1 - compress_rate))]\n",
    "        weight_np[weight_np <= -threshold] = 1\n",
    "        weight_np[weight_np >= threshold] = 1\n",
    "        weight_np[weight_np != 1] = 0\n",
    "\n",
    "        print(\"codebook done\")\n",
    "        return weight_np\n",
    "\n",
    "    def get_filter_codebook(self, weight_torch, compress_rate, length):\n",
    "        codebook = np.ones(length)\n",
    "        if len(weight_torch.size()) == 4:\n",
    "            filter_pruned_num = int(weight_torch.size()[0] * (1 - compress_rate))\n",
    "            weight_vec = weight_torch.view(weight_torch.size()[0], -1)\n",
    "            # norm1 = torch.norm(weight_vec, 1, 1)\n",
    "            # norm1_np = norm1.cpu().numpy()\n",
    "            norm2 = torch.norm(weight_vec, 2, 1)\n",
    "            norm2_np = norm2.cpu().numpy()\n",
    "            filter_index = norm2_np.argsort()[:filter_pruned_num]\n",
    "            #            norm1_sort = np.sort(norm1_np)\n",
    "            #            threshold = norm1_sort[int (weight_torch.size()[0] * (1-compress_rate) )]\n",
    "            kernel_length = weight_torch.size()[1] * weight_torch.size()[2] * weight_torch.size()[3]\n",
    "            for x in range(0, len(filter_index)):\n",
    "                codebook[filter_index[x] * kernel_length: (filter_index[x] + 1) * kernel_length] = 0\n",
    "\n",
    "            print(\"filter codebook done\")\n",
    "        else:\n",
    "            pass\n",
    "        return codebook\n",
    "\n",
    "    def convert2tensor(self, x):\n",
    "        x = torch.FloatTensor(x)\n",
    "        return x\n",
    "\n",
    "    def init_length(self):\n",
    "        for index, item in enumerate(self.model.parameters()):\n",
    "            self.model_size[index] = item.size()\n",
    "\n",
    "        for index1 in self.model_size:\n",
    "            for index2 in range(0, len(self.model_size[index1])):\n",
    "                if index2 == 0:\n",
    "                    self.model_length[index1] = self.model_size[index1][0]\n",
    "                else:\n",
    "                    self.model_length[index1] *= self.model_size[index1][index2]\n",
    "\n",
    "    def init_rate(self, layer_rate):\n",
    "        if 'vgg' in args.arch:\n",
    "            cfg_5x = [24, 22, 41, 51, 108, 89, 111, 184, 276, 228, 512, 512, 512]\n",
    "            cfg_official = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n",
    "            # cfg = [32, 64, 128, 128, 256, 256, 256, 256, 256, 256, 256, 256, 256]\n",
    "            cfg_index = 0\n",
    "            pre_cfg = True\n",
    "            for index, item in enumerate(self.model.named_parameters()):\n",
    "                self.compress_rate[index] = 1\n",
    "                if len(item[1].size()) == 4:\n",
    "                    print(item[1].size())\n",
    "                    if not pre_cfg:\n",
    "                        self.compress_rate[index] = layer_rate\n",
    "                        self.mask_index.append(index)\n",
    "                        print(item[0], \"self.mask_index\", self.mask_index)\n",
    "                    else:\n",
    "                        self.compress_rate[index] =  1 - cfg_5x[cfg_index] / item[1].size()[0]\n",
    "                        self.mask_index.append(index)\n",
    "                        print(item[0], \"self.mask_index\", self.mask_index, cfg_index, cfg_5x[cfg_index], item[1].size()[0],\n",
    "                               )\n",
    "                        cfg_index += 1\n",
    "        elif \"resnet\" in args.arch:\n",
    "            for index, item in enumerate(self.model.parameters()):\n",
    "                self.compress_rate[index] = 1\n",
    "            for key in range(args.layer_begin, args.layer_end + 1, args.layer_inter):\n",
    "                self.compress_rate[key] = layer_rate\n",
    "            if args.arch == 'resnet18':\n",
    "                # last index include last fc layer\n",
    "                last_index = 60\n",
    "                skip_list = [21, 36, 51]\n",
    "            elif args.arch == 'resnet34':\n",
    "                last_index = 108\n",
    "                skip_list = [27, 54, 93]\n",
    "            elif args.arch == 'resnet50':\n",
    "                last_index = 159\n",
    "                skip_list = [12, 42, 81, 138]\n",
    "            elif args.arch == 'resnet101':\n",
    "                last_index = 312\n",
    "                skip_list = [12, 42, 81, 291]\n",
    "            elif args.arch == 'resnet152':\n",
    "                last_index = 465\n",
    "                skip_list = [12, 42, 117, 444]\n",
    "            self.mask_index = [x for x in range(0, last_index, 3)]\n",
    "            # skip downsample layer\n",
    "            if args.skip_downsample == 1:\n",
    "                for x in skip_list:\n",
    "                    self.compress_rate[x] = 1\n",
    "                    self.mask_index.remove(x)\n",
    "                    print(self.mask_index)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def init_mask(self, layer_rate):\n",
    "        self.init_rate(layer_rate)\n",
    "        for index, item in enumerate(self.model.parameters()):\n",
    "            if (index in self.mask_index):\n",
    "                self.mat[index] = self.get_filter_codebook(item.data, self.compress_rate[index],\n",
    "                                                           self.model_length[index])\n",
    "                self.mat[index] = self.convert2tensor(self.mat[index])\n",
    "                if args.use_cuda:\n",
    "                    self.mat[index] = self.mat[index].cuda()\n",
    "        print(\"mask Ready\")\n",
    "\n",
    "    def do_mask(self):\n",
    "        for index, item in enumerate(self.model.parameters()):\n",
    "            if (index in self.mask_index):\n",
    "                a = item.data.view(self.model_length[index])\n",
    "                b = a * self.mat[index]\n",
    "                item.data = b.view(self.model_size[index])\n",
    "        print(\"mask Done\")\n",
    "\n",
    "    def if_zero(self):\n",
    "        for index, item in enumerate(self.model.parameters()):\n",
    "            #            if(index in self.mask_index):\n",
    "            if index in [x for x in range(args.layer_begin, args.layer_end + 1, args.layer_inter)]:\n",
    "                a = item.data.view(self.model_length[index])\n",
    "                b = a.cpu().numpy()\n",
    "\n",
    "                print(\"layer: %d, number of nonzero weight is %d, zero is %d\" % (\n",
    "                    index, np.count_nonzero(b), len(b) - np.count_nonzero(b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyThon  version : 3.7.0 (default, Oct  9 2018, 10:31:47)  [GCC 7.3.0]\n",
      "PyTorch version : 1.6.0+cu101\n",
      "cuDNN   version : 7603\n",
      "Vision  version : 0.7.0+cu101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_prec1 = 0\n",
    "\n",
    "if not os.path.isdir(args.save_dir):\n",
    "    os.makedirs(args.save_dir)\n",
    "log = open(os.path.join(args.save_dir, '{}.{}.log'.format(args.arch, args.prefix)), 'w')\n",
    "\n",
    "# version information\n",
    "print_log(\"PyThon  version : {}\".format(sys.version.replace('\\n', ' ')), log)\n",
    "print_log(\"PyTorch version : {}\".format(torch.__version__), log)\n",
    "print_log(\"cuDNN   version : {}\".format(torch.backends.cudnn.version()), log)\n",
    "print_log(\"Vision  version : {}\".format(torchvision.__version__), log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet101'\n",
      "=> Model : ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "=> parameter : DotMap(data='/home/hongky/datasets/imagenet', save_dir='0310_resnet101/resnet101-rate-0.7/', arch='resnet101', workers=8, epochs=10, start_epoch=0, batch_size=256, lr=0.1, momentum=0.9, weight_decay=0.0001, print_freq=200, resume='', evaluate=False, use_pretrain=True, rate=0.7, layer_begin=0, layer_end=309, layer_inter=3, epoch_prune=1, skip_downsample=1, use_sparse=False, sparse='', lr_adjust=30, use_cuda=True, prefix='2020-10-03-416')\n",
      "Compress Rate: 0.7\n",
      "Layer Begin: 0\n",
      "Layer End: 309\n",
      "Layer Inter: 3\n",
      "Epoch prune: 1\n",
      "Skip downsample : 1\n",
      "Workers         : 8\n",
      "Learning-Rate   : 0.1\n",
      "Use Pre-Trained : True\n",
      "lr adjust : 30\n",
      "Model::  DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# create model\n",
    "print_log(\"=> creating model '{}'\".format(args.arch), log)\n",
    "model = models.__dict__[args.arch](pretrained=True)\n",
    "if args.use_sparse:\n",
    "    model = import_sparse(model)\n",
    "print_log(\"=> Model : {}\".format(model), log)\n",
    "print_log(\"=> parameter : {}\".format(args), log)\n",
    "print_log(\"Compress Rate: {}\".format(args.rate), log)\n",
    "print_log(\"Layer Begin: {}\".format(args.layer_begin), log)\n",
    "print_log(\"Layer End: {}\".format(args.layer_end), log)\n",
    "print_log(\"Layer Inter: {}\".format(args.layer_inter), log)\n",
    "print_log(\"Epoch prune: {}\".format(args.epoch_prune), log)\n",
    "print_log(\"Skip downsample : {}\".format(args.skip_downsample), log)\n",
    "print_log(\"Workers         : {}\".format(args.workers), log)\n",
    "print_log(\"Learning-Rate   : {}\".format(args.lr), log)\n",
    "print_log(\"Use Pre-Trained : {}\".format(args.use_pretrain), log)\n",
    "print_log(\"lr adjust : {}\".format(args.lr_adjust), log)\n",
    "\n",
    "if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "    model.features = torch.nn.DataParallel(model.features)\n",
    "    model.cuda()\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    \n",
    "print('Model:: ', model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay,\n",
    "                            nesterov=True)\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print_log(\"=> loading checkpoint '{}'\".format(args.resume), log)\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print_log(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']), log)\n",
    "    else:\n",
    "        print_log(\"=> no checkpoint found at '{}'\".format(args.resume), log)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True, sampler=None)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------one epoch begin----------\n",
      "the compression rate now is 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:74: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/196]\tTime 12.922 (12.922)\tLoss 0.4331 (0.4331)\tPrec@1 87.891 (87.891)\tPrec@5 98.047 (98.047)\n",
      " * Prec@1 77.374 Prec@5 93.546 Error@1 22.626\n",
      ">>>>> Accuracy_origin_model: 77.374\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 294, 297, 300, 303, 306, 309]\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "mask Ready\n",
      "mask Done\n",
      "Test: [0/196]\tTime 5.334 (5.334)\tLoss 5.3062 (5.3062)\tPrec@1 1.953 (1.953)\tPrec@5 11.328 (11.328)\n",
      " * Prec@1 7.188 Prec@5 17.818 Error@1 92.812\n",
      ">>>>> Accuracy_masked_model: 7.188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = os.path.join(args.save_dir, 'checkpoint.{:}.{:}.pth.tar'.format(args.arch, args.prefix))\n",
    "bestname = os.path.join(args.save_dir, 'best.{:}.{:}.pth.tar'.format(args.arch, args.prefix))\n",
    "\n",
    "m = Mask(model)\n",
    "\n",
    "m.init_length()\n",
    "print(\"-\" * 10 + \"one epoch begin\" + \"-\" * 10)\n",
    "print(\"the compression rate now is {:}\".format(args.rate))\n",
    "\n",
    "val_acc_1 = validate(val_loader, model, criterion, log)\n",
    "\n",
    "print(\">>>>> Accuracy_origin_model: {:}\".format(val_acc_1))\n",
    "\n",
    "m.model = model\n",
    "\n",
    "m.init_mask(args.rate)\n",
    "# m.if_zero()\n",
    "m.do_mask()\n",
    "model = m.model\n",
    "# m.if_zero()\n",
    "if args.use_cuda:\n",
    "    model = model.cuda()\n",
    "val_acc_2 = validate(val_loader, model, criterion, log)\n",
    "print(\">>>>> Accuracy_masked_model: {:}\".format(val_acc_2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [resnet101] ::   0/ 10 ----- [[2020-10-03 06:10:45]] [Need: 00:00:00]\n",
      "Epoch: [0][0/5005]\tTime 39.941 (39.941)\tData 39.561 (39.561)\tLoss 3.0013 (3.0013)\tPrec@1 48.828 (48.828)\tPrec@5 70.703 (70.703)\n",
      "Epoch: [0][200/5005]\tTime 16.031 (3.066)\tData 15.661 (2.706)\tLoss 3.4957 (4.0360)\tPrec@1 26.953 (20.171)\tPrec@5 55.078 (42.671)\n",
      "Epoch: [0][400/5005]\tTime 11.497 (2.753)\tData 11.148 (2.393)\tLoss 3.2045 (3.6638)\tPrec@1 31.250 (25.375)\tPrec@5 56.250 (49.606)\n",
      "Epoch: [0][600/5005]\tTime 5.994 (2.699)\tData 5.645 (2.340)\tLoss 2.9800 (3.4551)\tPrec@1 37.109 (28.572)\tPrec@5 62.500 (53.475)\n",
      "Epoch: [0][800/5005]\tTime 2.770 (2.706)\tData 2.423 (2.346)\tLoss 3.0512 (3.3140)\tPrec@1 35.156 (30.789)\tPrec@5 62.109 (56.055)\n",
      "Epoch: [0][1000/5005]\tTime 4.086 (2.679)\tData 3.737 (2.319)\tLoss 2.6420 (3.2096)\tPrec@1 42.188 (32.476)\tPrec@5 65.625 (57.899)\n",
      "Epoch: [0][1200/5005]\tTime 8.221 (2.674)\tData 7.870 (2.314)\tLoss 2.6672 (3.1249)\tPrec@1 38.281 (33.876)\tPrec@5 67.969 (59.396)\n",
      "Epoch: [0][1400/5005]\tTime 2.269 (2.689)\tData 1.814 (2.330)\tLoss 2.4230 (3.0577)\tPrec@1 45.312 (34.999)\tPrec@5 75.781 (60.607)\n",
      "Epoch: [0][1600/5005]\tTime 0.892 (2.676)\tData 0.544 (2.317)\tLoss 2.6602 (2.9969)\tPrec@1 40.625 (36.067)\tPrec@5 68.750 (61.655)\n",
      "Epoch: [0][1800/5005]\tTime 2.638 (2.672)\tData 2.290 (2.313)\tLoss 2.5817 (2.9458)\tPrec@1 43.750 (36.960)\tPrec@5 66.797 (62.551)\n",
      "Epoch: [0][2000/5005]\tTime 5.916 (2.683)\tData 5.567 (2.319)\tLoss 2.4515 (2.9012)\tPrec@1 46.094 (37.754)\tPrec@5 71.094 (63.323)\n",
      "Epoch: [0][2200/5005]\tTime 8.868 (2.690)\tData 8.433 (2.319)\tLoss 2.3448 (2.8608)\tPrec@1 48.438 (38.466)\tPrec@5 68.750 (64.013)\n",
      "Epoch: [0][2400/5005]\tTime 5.378 (2.675)\tData 4.942 (2.298)\tLoss 2.3451 (2.8261)\tPrec@1 49.609 (39.097)\tPrec@5 73.438 (64.599)\n",
      "Epoch: [0][2600/5005]\tTime 5.089 (2.662)\tData 4.653 (2.280)\tLoss 2.3994 (2.7929)\tPrec@1 49.219 (39.695)\tPrec@5 72.656 (65.169)\n",
      "Epoch: [0][2800/5005]\tTime 13.015 (2.632)\tData 12.588 (2.246)\tLoss 2.4048 (2.7635)\tPrec@1 44.531 (40.223)\tPrec@5 73.047 (65.664)\n",
      "Epoch: [0][3000/5005]\tTime 14.345 (2.613)\tData 13.916 (2.224)\tLoss 2.2456 (2.7359)\tPrec@1 53.516 (40.733)\tPrec@5 76.953 (66.122)\n",
      "Epoch: [0][3200/5005]\tTime 19.054 (2.611)\tData 18.526 (2.218)\tLoss 2.2358 (2.7106)\tPrec@1 46.875 (41.171)\tPrec@5 75.391 (66.548)\n",
      "Epoch: [0][3400/5005]\tTime 12.288 (2.631)\tData 11.850 (2.235)\tLoss 2.3449 (2.6880)\tPrec@1 45.703 (41.579)\tPrec@5 70.703 (66.918)\n",
      "Epoch: [0][3600/5005]\tTime 17.463 (2.647)\tData 17.024 (2.249)\tLoss 2.1641 (2.6673)\tPrec@1 49.219 (41.966)\tPrec@5 78.125 (67.266)\n",
      "Epoch: [0][3800/5005]\tTime 12.667 (2.650)\tData 12.234 (2.250)\tLoss 2.2169 (2.6486)\tPrec@1 50.781 (42.297)\tPrec@5 74.609 (67.579)\n",
      "Epoch: [0][4000/5005]\tTime 5.224 (2.651)\tData 4.795 (2.248)\tLoss 2.3122 (2.6308)\tPrec@1 46.875 (42.630)\tPrec@5 74.219 (67.867)\n",
      "Epoch: [0][4200/5005]\tTime 7.073 (2.644)\tData 6.636 (2.239)\tLoss 2.0546 (2.6146)\tPrec@1 53.516 (42.929)\tPrec@5 81.250 (68.133)\n",
      "Epoch: [0][4400/5005]\tTime 7.947 (2.632)\tData 7.508 (2.226)\tLoss 2.2943 (2.5990)\tPrec@1 48.438 (43.228)\tPrec@5 74.219 (68.394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][4600/5005]\tTime 10.827 (2.621)\tData 10.392 (2.214)\tLoss 2.2570 (2.5846)\tPrec@1 48.438 (43.501)\tPrec@5 74.219 (68.628)\n",
      "Epoch: [0][4800/5005]\tTime 14.158 (2.614)\tData 13.723 (2.205)\tLoss 2.2274 (2.5709)\tPrec@1 53.516 (43.755)\tPrec@5 73.438 (68.853)\n",
      "Epoch: [0][5000/5005]\tTime 10.839 (2.610)\tData 10.313 (2.200)\tLoss 2.1723 (2.5571)\tPrec@1 50.391 (44.013)\tPrec@5 74.219 (69.084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:74: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/196]\tTime 8.641 (8.641)\tLoss 1.3524 (1.3524)\tPrec@1 66.016 (66.016)\tPrec@5 87.891 (87.891)\n",
      " * Prec@1 51.786 Prec@5 77.592 Error@1 48.214\n",
      "\n",
      "\n",
      ">>>>> Accuracy_model:  51.786\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 26325, zero is 10539\n",
      "layer: 9, number of nonzero weight is 13774, zero is 2610\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 26253, zero is 10611\n",
      "layer: 21, number of nonzero weight is 14204, zero is 2180\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 27135, zero is 9729\n",
      "layer: 30, number of nonzero weight is 15168, zero is 1216\n",
      "layer: 33, number of nonzero weight is 23296, zero is 9472\n",
      "layer: 36, number of nonzero weight is 121698, zero is 25758\n",
      "layer: 39, number of nonzero weight is 55904, zero is 9632\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 51001, zero is 14535\n",
      "layer: 48, number of nonzero weight is 106407, zero is 41049\n",
      "layer: 51, number of nonzero weight is 57577, zero is 7959\n",
      "layer: 54, number of nonzero weight is 49468, zero is 16068\n",
      "layer: 57, number of nonzero weight is 112410, zero is 35046\n",
      "layer: 60, number of nonzero weight is 60452, zero is 5084\n",
      "layer: 63, number of nonzero weight is 50616, zero is 14920\n",
      "layer: 66, number of nonzero weight is 108135, zero is 39321\n",
      "layer: 69, number of nonzero weight is 60487, zero is 5049\n",
      "layer: 72, number of nonzero weight is 93184, zero is 37888\n",
      "layer: 75, number of nonzero weight is 442566, zero is 147258\n",
      "layer: 78, number of nonzero weight is 226889, zero is 35255\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 196501, zero is 65643\n",
      "layer: 87, number of nonzero weight is 419931, zero is 169893\n",
      "layer: 90, number of nonzero weight is 230217, zero is 31927\n",
      "layer: 93, number of nonzero weight is 206676, zero is 55468\n",
      "layer: 96, number of nonzero weight is 416547, zero is 173277\n",
      "layer: 99, number of nonzero weight is 232419, zero is 29725\n",
      "layer: 102, number of nonzero weight is 194187, zero is 67957\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 233232, zero is 28912\n",
      "layer: 111, number of nonzero weight is 194246, zero is 67898\n",
      "layer: 114, number of nonzero weight is 416430, zero is 173394\n",
      "layer: 117, number of nonzero weight is 234952, zero is 27192\n",
      "layer: 120, number of nonzero weight is 185321, zero is 76823\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 235024, zero is 27120\n",
      "layer: 129, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 235017, zero is 27127\n",
      "layer: 138, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 235572, zero is 26572\n",
      "layer: 147, number of nonzero weight is 185326, zero is 76818\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 235745, zero is 26399\n",
      "layer: 156, number of nonzero weight is 191361, zero is 70783\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 238086, zero is 24058\n",
      "layer: 165, number of nonzero weight is 185339, zero is 76805\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 238452, zero is 23692\n",
      "layer: 174, number of nonzero weight is 186363, zero is 75781\n",
      "layer: 177, number of nonzero weight is 422910, zero is 166914\n",
      "layer: 180, number of nonzero weight is 240345, zero is 21799\n",
      "layer: 183, number of nonzero weight is 189438, zero is 72706\n",
      "layer: 186, number of nonzero weight is 418050, zero is 171774\n",
      "layer: 189, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 192, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 195, number of nonzero weight is 417996, zero is 171828\n",
      "layer: 198, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 201, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 210, number of nonzero weight is 187392, zero is 74752\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 219, number of nonzero weight is 188416, zero is 73728\n",
      "layer: 222, number of nonzero weight is 416376, zero is 173448\n",
      "layer: 225, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 228, number of nonzero weight is 189440, zero is 72704\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 237, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 240, number of nonzero weight is 416358, zero is 173466\n",
      "layer: 243, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 246, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 264, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 737280, zero is 311296\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1657503, zero is 701793\n",
      "layer: 309, number of nonzero weight is 955248, zero is 93328\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 294, 297, 300, 303, 306, 309]\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "mask Ready\n",
      "mask Done\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 25749, zero is 11115\n",
      "layer: 9, number of nonzero weight is 11376, zero is 5008\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 21, number of nonzero weight is 11100, zero is 5284\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 25407, zero is 11457\n",
      "layer: 30, number of nonzero weight is 11168, zero is 5216\n",
      "layer: 33, number of nonzero weight is 23040, zero is 9728\n",
      "layer: 36, number of nonzero weight is 96354, zero is 51102\n",
      "layer: 39, number of nonzero weight is 45584, zero is 19952\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 45561, zero is 19975\n",
      "layer: 48, number of nonzero weight is 103437, zero is 44019\n",
      "layer: 51, number of nonzero weight is 44272, zero is 21264\n",
      "layer: 54, number of nonzero weight is 45884, zero is 19652\n",
      "layer: 57, number of nonzero weight is 100890, zero is 46566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 60, number of nonzero weight is 44916, zero is 20620\n",
      "layer: 63, number of nonzero weight is 46008, zero is 19528\n",
      "layer: 66, number of nonzero weight is 102375, zero is 45081\n",
      "layer: 69, number of nonzero weight is 45193, zero is 20343\n",
      "layer: 72, number of nonzero weight is 92160, zero is 38912\n",
      "layer: 75, number of nonzero weight is 403398, zero is 186426\n",
      "layer: 78, number of nonzero weight is 183316, zero is 78828\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 183711, zero is 78433\n",
      "layer: 87, number of nonzero weight is 413586, zero is 176238\n",
      "layer: 90, number of nonzero weight is 176763, zero is 85381\n",
      "layer: 93, number of nonzero weight is 183280, zero is 78864\n",
      "layer: 96, number of nonzero weight is 414243, zero is 175581\n",
      "layer: 99, number of nonzero weight is 178002, zero is 84142\n",
      "layer: 102, number of nonzero weight is 183947, zero is 78197\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 174736, zero is 87408\n",
      "layer: 111, number of nonzero weight is 184037, zero is 78107\n",
      "layer: 114, number of nonzero weight is 414126, zero is 175698\n",
      "layer: 117, number of nonzero weight is 175002, zero is 87142\n",
      "layer: 120, number of nonzero weight is 184297, zero is 77847\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 175344, zero is 86800\n",
      "layer: 129, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 177168, zero is 84976\n",
      "layer: 138, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 179904, zero is 82240\n",
      "layer: 147, number of nonzero weight is 184302, zero is 77842\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 179980, zero is 82164\n",
      "layer: 156, number of nonzero weight is 184193, zero is 77951\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 182032, zero is 80112\n",
      "layer: 165, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 181500, zero is 80644\n",
      "layer: 174, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 177, number of nonzero weight is 411390, zero is 178434\n",
      "layer: 180, number of nonzero weight is 181138, zero is 81006\n",
      "layer: 183, number of nonzero weight is 184318, zero is 77826\n",
      "layer: 186, number of nonzero weight is 413442, zero is 176382\n",
      "layer: 189, number of nonzero weight is 182368, zero is 79776\n",
      "layer: 192, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 195, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 198, number of nonzero weight is 182442, zero is 79702\n",
      "layer: 201, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 181956, zero is 80188\n",
      "layer: 210, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 180132, zero is 82012\n",
      "layer: 219, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 222, number of nonzero weight is 414072, zero is 175752\n",
      "layer: 225, number of nonzero weight is 180702, zero is 81442\n",
      "layer: 228, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 180056, zero is 82088\n",
      "layer: 237, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 240, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 243, number of nonzero weight is 181377, zero is 80767\n",
      "layer: 246, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 182336, zero is 79808\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 182640, zero is 79504\n",
      "layer: 264, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 182108, zero is 80036\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 182260, zero is 79884\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 732831, zero is 315745\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 732984, zero is 315592\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1652895, zero is 706401\n",
      "layer: 309, number of nonzero weight is 730864, zero is 317712\n",
      "Test: [0/196]\tTime 5.265 (5.265)\tLoss 1.4465 (1.4465)\tPrec@1 64.453 (64.453)\tPrec@5 87.500 (87.500)\n",
      " * Prec@1 46.826 Prec@5 73.346 Error@1 53.174\n",
      "\n",
      "\n",
      ">>>>> Accuracy_pruned:  46.826\n",
      " [resnet101] ::   1/ 10 ----- [[2020-10-03 09:52:22]] [Need: 33:14:33]\n",
      "Epoch: [1][0/5005]\tTime 28.333 (28.333)\tData 27.761 (27.761)\tLoss 2.1359 (2.1359)\tPrec@1 51.172 (51.172)\tPrec@5 76.172 (76.172)\n",
      "Epoch: [1][200/5005]\tTime 14.315 (2.878)\tData 13.876 (2.434)\tLoss 2.4023 (2.2222)\tPrec@1 45.312 (49.940)\tPrec@5 70.703 (74.672)\n",
      "Epoch: [1][400/5005]\tTime 11.291 (2.638)\tData 10.855 (2.194)\tLoss 2.2466 (2.2178)\tPrec@1 54.297 (50.119)\tPrec@5 72.266 (74.730)\n",
      "Epoch: [1][600/5005]\tTime 9.693 (2.597)\tData 9.256 (2.153)\tLoss 2.3925 (2.2197)\tPrec@1 47.266 (50.116)\tPrec@5 71.094 (74.611)\n",
      "Epoch: [1][800/5005]\tTime 2.409 (2.553)\tData 2.055 (2.123)\tLoss 2.1499 (2.2148)\tPrec@1 51.953 (50.263)\tPrec@5 75.391 (74.684)\n",
      "Epoch: [1][1000/5005]\tTime 4.735 (2.502)\tData 4.385 (2.087)\tLoss 2.1611 (2.2129)\tPrec@1 51.172 (50.296)\tPrec@5 73.828 (74.706)\n",
      "Epoch: [1][1200/5005]\tTime 11.855 (2.496)\tData 11.489 (2.090)\tLoss 2.3813 (2.2094)\tPrec@1 46.094 (50.327)\tPrec@5 71.094 (74.757)\n",
      "Epoch: [1][1400/5005]\tTime 11.011 (2.469)\tData 10.643 (2.070)\tLoss 2.2762 (2.2078)\tPrec@1 53.125 (50.371)\tPrec@5 77.344 (74.794)\n",
      "Epoch: [1][1600/5005]\tTime 14.769 (2.470)\tData 14.420 (2.076)\tLoss 2.0481 (2.2045)\tPrec@1 50.000 (50.460)\tPrec@5 80.078 (74.845)\n",
      "Epoch: [1][1800/5005]\tTime 14.809 (2.486)\tData 14.336 (2.095)\tLoss 2.4810 (2.2045)\tPrec@1 46.484 (50.462)\tPrec@5 69.141 (74.851)\n",
      "Epoch: [1][2000/5005]\tTime 12.564 (2.510)\tData 12.214 (2.121)\tLoss 2.0354 (2.2017)\tPrec@1 56.250 (50.506)\tPrec@5 78.906 (74.905)\n",
      "Epoch: [1][2200/5005]\tTime 13.641 (2.525)\tData 13.273 (2.140)\tLoss 2.0653 (2.2009)\tPrec@1 55.078 (50.490)\tPrec@5 77.344 (74.932)\n",
      "Epoch: [1][2400/5005]\tTime 9.026 (2.536)\tData 8.676 (2.153)\tLoss 2.3777 (2.1985)\tPrec@1 43.359 (50.541)\tPrec@5 69.531 (74.978)\n",
      "Epoch: [1][2600/5005]\tTime 12.162 (2.536)\tData 11.792 (2.154)\tLoss 2.3749 (2.1975)\tPrec@1 52.734 (50.557)\tPrec@5 72.656 (75.007)\n",
      "Epoch: [1][2800/5005]\tTime 10.847 (2.537)\tData 10.475 (2.156)\tLoss 2.1417 (2.1943)\tPrec@1 54.688 (50.634)\tPrec@5 73.828 (75.053)\n",
      "Epoch: [1][3000/5005]\tTime 12.652 (2.538)\tData 12.285 (2.158)\tLoss 2.1400 (2.1922)\tPrec@1 55.078 (50.680)\tPrec@5 73.828 (75.093)\n",
      "Epoch: [1][3200/5005]\tTime 8.775 (2.539)\tData 8.424 (2.161)\tLoss 2.2954 (2.1909)\tPrec@1 49.609 (50.706)\tPrec@5 72.266 (75.114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][3400/5005]\tTime 4.528 (2.540)\tData 4.176 (2.162)\tLoss 2.0469 (2.1895)\tPrec@1 51.953 (50.729)\tPrec@5 77.734 (75.121)\n",
      "Epoch: [1][3600/5005]\tTime 6.718 (2.549)\tData 6.264 (2.173)\tLoss 1.9813 (2.1886)\tPrec@1 51.172 (50.751)\tPrec@5 82.031 (75.136)\n",
      "Epoch: [1][3800/5005]\tTime 2.333 (2.549)\tData 1.983 (2.173)\tLoss 1.9458 (2.1868)\tPrec@1 53.125 (50.783)\tPrec@5 80.859 (75.157)\n",
      "Epoch: [1][4000/5005]\tTime 10.893 (2.564)\tData 10.544 (2.189)\tLoss 2.1426 (2.1858)\tPrec@1 50.000 (50.794)\tPrec@5 77.344 (75.177)\n",
      "Epoch: [1][4200/5005]\tTime 17.706 (2.566)\tData 17.357 (2.192)\tLoss 2.2829 (2.1851)\tPrec@1 48.047 (50.802)\tPrec@5 76.172 (75.182)\n",
      "Epoch: [1][4400/5005]\tTime 18.178 (2.569)\tData 17.828 (2.196)\tLoss 2.2217 (2.1834)\tPrec@1 50.781 (50.834)\tPrec@5 73.438 (75.207)\n",
      "Epoch: [1][4600/5005]\tTime 12.863 (2.557)\tData 12.512 (2.184)\tLoss 2.2871 (2.1828)\tPrec@1 49.609 (50.847)\tPrec@5 72.656 (75.224)\n",
      "Epoch: [1][4800/5005]\tTime 6.205 (2.539)\tData 5.851 (2.166)\tLoss 2.0418 (2.1819)\tPrec@1 51.562 (50.882)\tPrec@5 74.219 (75.240)\n",
      "Epoch: [1][5000/5005]\tTime 2.576 (2.529)\tData 2.227 (2.157)\tLoss 2.2181 (2.1805)\tPrec@1 51.953 (50.916)\tPrec@5 73.828 (75.264)\n",
      "Test: [0/196]\tTime 9.049 (9.049)\tLoss 1.3477 (1.3477)\tPrec@1 66.406 (66.406)\tPrec@5 90.234 (90.234)\n",
      " * Prec@1 54.860 Prec@5 80.136 Error@1 45.140\n",
      "\n",
      "\n",
      ">>>>> Accuracy_model:  54.86\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 26325, zero is 10539\n",
      "layer: 9, number of nonzero weight is 13774, zero is 2610\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 26253, zero is 10611\n",
      "layer: 21, number of nonzero weight is 14204, zero is 2180\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 27135, zero is 9729\n",
      "layer: 30, number of nonzero weight is 15168, zero is 1216\n",
      "layer: 33, number of nonzero weight is 23296, zero is 9472\n",
      "layer: 36, number of nonzero weight is 121698, zero is 25758\n",
      "layer: 39, number of nonzero weight is 55904, zero is 9632\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 51001, zero is 14535\n",
      "layer: 48, number of nonzero weight is 106407, zero is 41049\n",
      "layer: 51, number of nonzero weight is 57577, zero is 7959\n",
      "layer: 54, number of nonzero weight is 49468, zero is 16068\n",
      "layer: 57, number of nonzero weight is 112410, zero is 35046\n",
      "layer: 60, number of nonzero weight is 60452, zero is 5084\n",
      "layer: 63, number of nonzero weight is 50616, zero is 14920\n",
      "layer: 66, number of nonzero weight is 108135, zero is 39321\n",
      "layer: 69, number of nonzero weight is 60487, zero is 5049\n",
      "layer: 72, number of nonzero weight is 93184, zero is 37888\n",
      "layer: 75, number of nonzero weight is 442566, zero is 147258\n",
      "layer: 78, number of nonzero weight is 226889, zero is 35255\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 196501, zero is 65643\n",
      "layer: 87, number of nonzero weight is 419931, zero is 169893\n",
      "layer: 90, number of nonzero weight is 230217, zero is 31927\n",
      "layer: 93, number of nonzero weight is 206676, zero is 55468\n",
      "layer: 96, number of nonzero weight is 416547, zero is 173277\n",
      "layer: 99, number of nonzero weight is 232419, zero is 29725\n",
      "layer: 102, number of nonzero weight is 194187, zero is 67957\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 233232, zero is 28912\n",
      "layer: 111, number of nonzero weight is 194246, zero is 67898\n",
      "layer: 114, number of nonzero weight is 416430, zero is 173394\n",
      "layer: 117, number of nonzero weight is 234952, zero is 27192\n",
      "layer: 120, number of nonzero weight is 185321, zero is 76823\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 235024, zero is 27120\n",
      "layer: 129, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 235017, zero is 27127\n",
      "layer: 138, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 235572, zero is 26572\n",
      "layer: 147, number of nonzero weight is 185326, zero is 76818\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 235745, zero is 26399\n",
      "layer: 156, number of nonzero weight is 191361, zero is 70783\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 238086, zero is 24058\n",
      "layer: 165, number of nonzero weight is 185339, zero is 76805\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 238452, zero is 23692\n",
      "layer: 174, number of nonzero weight is 186363, zero is 75781\n",
      "layer: 177, number of nonzero weight is 422910, zero is 166914\n",
      "layer: 180, number of nonzero weight is 240345, zero is 21799\n",
      "layer: 183, number of nonzero weight is 189438, zero is 72706\n",
      "layer: 186, number of nonzero weight is 418050, zero is 171774\n",
      "layer: 189, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 192, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 195, number of nonzero weight is 417996, zero is 171828\n",
      "layer: 198, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 201, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 210, number of nonzero weight is 187392, zero is 74752\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 219, number of nonzero weight is 188416, zero is 73728\n",
      "layer: 222, number of nonzero weight is 416376, zero is 173448\n",
      "layer: 225, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 228, number of nonzero weight is 189440, zero is 72704\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 237, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 240, number of nonzero weight is 416358, zero is 173466\n",
      "layer: 243, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 246, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 264, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 737280, zero is 311296\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1657503, zero is 701793\n",
      "layer: 309, number of nonzero weight is 955248, zero is 93328\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 294, 297, 300, 303, 306, 309]\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "mask Ready\n",
      "mask Done\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 25749, zero is 11115\n",
      "layer: 9, number of nonzero weight is 11358, zero is 5026\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 21, number of nonzero weight is 11080, zero is 5304\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 25407, zero is 11457\n",
      "layer: 30, number of nonzero weight is 11136, zero is 5248\n",
      "layer: 33, number of nonzero weight is 23040, zero is 9728\n",
      "layer: 36, number of nonzero weight is 99018, zero is 48438\n",
      "layer: 39, number of nonzero weight is 45584, zero is 19952\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 45625, zero is 19911\n",
      "layer: 48, number of nonzero weight is 103437, zero is 44019\n",
      "layer: 51, number of nonzero weight is 44237, zero is 21299\n",
      "layer: 54, number of nonzero weight is 45912, zero is 19624\n",
      "layer: 57, number of nonzero weight is 100890, zero is 46566\n",
      "layer: 60, number of nonzero weight is 44888, zero is 20648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 63, number of nonzero weight is 46008, zero is 19528\n",
      "layer: 66, number of nonzero weight is 102636, zero is 44820\n",
      "layer: 69, number of nonzero weight is 45028, zero is 20508\n",
      "layer: 72, number of nonzero weight is 92160, zero is 38912\n",
      "layer: 75, number of nonzero weight is 406728, zero is 183096\n",
      "layer: 78, number of nonzero weight is 183257, zero is 78887\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 183711, zero is 78433\n",
      "layer: 87, number of nonzero weight is 413586, zero is 176238\n",
      "layer: 90, number of nonzero weight is 175960, zero is 86184\n",
      "layer: 93, number of nonzero weight is 183540, zero is 78604\n",
      "layer: 96, number of nonzero weight is 414243, zero is 175581\n",
      "layer: 99, number of nonzero weight is 177027, zero is 85117\n",
      "layer: 102, number of nonzero weight is 183984, zero is 78160\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 173900, zero is 88244\n",
      "layer: 111, number of nonzero weight is 184068, zero is 78076\n",
      "layer: 114, number of nonzero weight is 414126, zero is 175698\n",
      "layer: 117, number of nonzero weight is 174477, zero is 87667\n",
      "layer: 120, number of nonzero weight is 184297, zero is 77847\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 174660, zero is 87484\n",
      "layer: 129, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 176408, zero is 85736\n",
      "layer: 138, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 179220, zero is 82924\n",
      "layer: 147, number of nonzero weight is 184302, zero is 77842\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 179372, zero is 82772\n",
      "layer: 156, number of nonzero weight is 184193, zero is 77951\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 181728, zero is 80416\n",
      "layer: 165, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 181196, zero is 80948\n",
      "layer: 174, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 177, number of nonzero weight is 411390, zero is 178434\n",
      "layer: 180, number of nonzero weight is 180641, zero is 81503\n",
      "layer: 183, number of nonzero weight is 184318, zero is 77826\n",
      "layer: 186, number of nonzero weight is 413442, zero is 176382\n",
      "layer: 189, number of nonzero weight is 182294, zero is 79850\n",
      "layer: 192, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 195, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 198, number of nonzero weight is 182516, zero is 79628\n",
      "layer: 201, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 181956, zero is 80188\n",
      "layer: 210, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 179676, zero is 82468\n",
      "layer: 219, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 222, number of nonzero weight is 414072, zero is 175752\n",
      "layer: 225, number of nonzero weight is 180252, zero is 81892\n",
      "layer: 228, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 179600, zero is 82544\n",
      "layer: 237, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 240, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 243, number of nonzero weight is 181152, zero is 80992\n",
      "layer: 246, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 182184, zero is 79960\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 182640, zero is 79504\n",
      "layer: 264, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 181880, zero is 80264\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 182260, zero is 79884\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 732831, zero is 315745\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 732984, zero is 315592\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1652895, zero is 706401\n",
      "layer: 309, number of nonzero weight is 730864, zero is 317712\n",
      "Test: [0/196]\tTime 4.181 (4.181)\tLoss 1.3640 (1.3640)\tPrec@1 66.406 (66.406)\tPrec@5 89.844 (89.844)\n",
      " * Prec@1 52.848 Prec@5 78.208 Error@1 47.152\n",
      "\n",
      "\n",
      ">>>>> Accuracy_pruned:  52.848\n",
      " [resnet101] ::   2/ 10 ----- [[2020-10-03 13:27:10]] [Need: 28:38:25]\n",
      "Epoch: [2][0/5005]\tTime 29.270 (29.270)\tData 28.857 (28.857)\tLoss 2.2129 (2.2129)\tPrec@1 50.781 (50.781)\tPrec@5 74.609 (74.609)\n",
      "Epoch: [2][200/5005]\tTime 18.122 (2.592)\tData 17.752 (2.231)\tLoss 2.0154 (2.1258)\tPrec@1 55.859 (52.043)\tPrec@5 75.781 (76.184)\n",
      "Epoch: [2][400/5005]\tTime 18.223 (2.517)\tData 17.767 (2.156)\tLoss 2.3112 (2.1305)\tPrec@1 50.000 (51.790)\tPrec@5 72.656 (76.027)\n",
      "Epoch: [2][600/5005]\tTime 14.344 (2.461)\tData 13.995 (2.101)\tLoss 1.9729 (2.1285)\tPrec@1 57.031 (51.827)\tPrec@5 78.516 (76.072)\n",
      "Epoch: [2][800/5005]\tTime 10.795 (2.401)\tData 10.433 (2.041)\tLoss 2.2148 (2.1331)\tPrec@1 49.219 (51.779)\tPrec@5 73.047 (75.963)\n",
      "Epoch: [2][1000/5005]\tTime 13.194 (2.371)\tData 12.844 (2.010)\tLoss 1.9943 (2.1292)\tPrec@1 57.422 (51.871)\tPrec@5 78.906 (76.012)\n",
      "Epoch: [2][1200/5005]\tTime 15.674 (2.386)\tData 15.307 (2.025)\tLoss 2.0845 (2.1290)\tPrec@1 53.906 (51.922)\tPrec@5 76.953 (76.009)\n",
      "Epoch: [2][1400/5005]\tTime 20.641 (2.430)\tData 20.291 (2.069)\tLoss 2.0290 (2.1292)\tPrec@1 55.469 (51.873)\tPrec@5 78.125 (76.030)\n",
      "Epoch: [2][1600/5005]\tTime 16.877 (2.465)\tData 16.527 (2.105)\tLoss 2.2542 (2.1275)\tPrec@1 46.484 (51.878)\tPrec@5 72.656 (76.055)\n",
      "Epoch: [2][1800/5005]\tTime 17.465 (2.481)\tData 17.115 (2.120)\tLoss 2.1790 (2.1307)\tPrec@1 51.562 (51.842)\tPrec@5 72.266 (76.019)\n",
      "Epoch: [2][2000/5005]\tTime 18.191 (2.499)\tData 17.829 (2.138)\tLoss 2.2296 (2.1327)\tPrec@1 51.172 (51.831)\tPrec@5 74.219 (76.005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][2200/5005]\tTime 17.209 (2.492)\tData 16.756 (2.131)\tLoss 2.4277 (2.1336)\tPrec@1 46.875 (51.818)\tPrec@5 73.047 (75.981)\n",
      "Epoch: [2][2400/5005]\tTime 18.595 (2.496)\tData 18.245 (2.135)\tLoss 2.2565 (2.1340)\tPrec@1 50.000 (51.818)\tPrec@5 73.047 (75.984)\n",
      "Epoch: [2][2600/5005]\tTime 17.748 (2.496)\tData 17.399 (2.135)\tLoss 2.2137 (2.1350)\tPrec@1 53.516 (51.810)\tPrec@5 72.656 (75.953)\n",
      "Epoch: [2][2800/5005]\tTime 12.825 (2.473)\tData 12.476 (2.112)\tLoss 1.9552 (2.1347)\tPrec@1 55.469 (51.830)\tPrec@5 80.469 (75.974)\n",
      "Epoch: [2][3000/5005]\tTime 6.734 (2.448)\tData 6.385 (2.088)\tLoss 2.0306 (2.1331)\tPrec@1 51.953 (51.870)\tPrec@5 78.516 (76.004)\n",
      "Epoch: [2][3200/5005]\tTime 11.925 (2.461)\tData 11.575 (2.100)\tLoss 2.1927 (2.1322)\tPrec@1 50.781 (51.890)\tPrec@5 75.781 (76.013)\n",
      "Epoch: [2][3400/5005]\tTime 14.448 (2.474)\tData 14.097 (2.114)\tLoss 2.2357 (2.1341)\tPrec@1 46.875 (51.856)\tPrec@5 71.875 (75.984)\n",
      "Epoch: [2][3600/5005]\tTime 14.331 (2.492)\tData 13.981 (2.132)\tLoss 2.1124 (2.1341)\tPrec@1 50.391 (51.849)\tPrec@5 76.953 (75.991)\n",
      "Epoch: [2][3800/5005]\tTime 18.845 (2.499)\tData 18.497 (2.139)\tLoss 1.9284 (2.1352)\tPrec@1 53.906 (51.817)\tPrec@5 79.297 (75.981)\n",
      "Epoch: [2][4000/5005]\tTime 16.063 (2.502)\tData 15.598 (2.142)\tLoss 2.1391 (2.1342)\tPrec@1 53.125 (51.837)\tPrec@5 76.172 (75.995)\n",
      "Epoch: [2][4200/5005]\tTime 16.489 (2.499)\tData 16.121 (2.139)\tLoss 1.9647 (2.1341)\tPrec@1 55.469 (51.840)\tPrec@5 77.734 (75.994)\n",
      "Epoch: [2][4400/5005]\tTime 16.442 (2.498)\tData 16.093 (2.138)\tLoss 1.8379 (2.1338)\tPrec@1 54.688 (51.838)\tPrec@5 83.203 (75.998)\n",
      "Epoch: [2][4600/5005]\tTime 16.155 (2.494)\tData 15.805 (2.134)\tLoss 2.0954 (2.1334)\tPrec@1 52.734 (51.840)\tPrec@5 78.125 (76.008)\n",
      "Epoch: [2][4800/5005]\tTime 13.511 (2.493)\tData 13.149 (2.133)\tLoss 2.2321 (2.1331)\tPrec@1 50.000 (51.846)\tPrec@5 75.000 (76.019)\n",
      "Epoch: [2][5000/5005]\tTime 13.821 (2.489)\tData 13.454 (2.128)\tLoss 2.1667 (2.1327)\tPrec@1 57.422 (51.850)\tPrec@5 76.172 (76.030)\n",
      "Test: [0/196]\tTime 8.735 (8.735)\tLoss 0.9408 (0.9408)\tPrec@1 73.047 (73.047)\tPrec@5 95.312 (95.312)\n",
      " * Prec@1 55.728 Prec@5 80.952 Error@1 44.272\n",
      "\n",
      "\n",
      ">>>>> Accuracy_model:  55.728\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 26325, zero is 10539\n",
      "layer: 9, number of nonzero weight is 13774, zero is 2610\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 26253, zero is 10611\n",
      "layer: 21, number of nonzero weight is 14204, zero is 2180\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 27135, zero is 9729\n",
      "layer: 30, number of nonzero weight is 15168, zero is 1216\n",
      "layer: 33, number of nonzero weight is 23296, zero is 9472\n",
      "layer: 36, number of nonzero weight is 121698, zero is 25758\n",
      "layer: 39, number of nonzero weight is 55904, zero is 9632\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 51001, zero is 14535\n",
      "layer: 48, number of nonzero weight is 106407, zero is 41049\n",
      "layer: 51, number of nonzero weight is 57577, zero is 7959\n",
      "layer: 54, number of nonzero weight is 49468, zero is 16068\n",
      "layer: 57, number of nonzero weight is 112410, zero is 35046\n",
      "layer: 60, number of nonzero weight is 60452, zero is 5084\n",
      "layer: 63, number of nonzero weight is 50616, zero is 14920\n",
      "layer: 66, number of nonzero weight is 108135, zero is 39321\n",
      "layer: 69, number of nonzero weight is 60487, zero is 5049\n",
      "layer: 72, number of nonzero weight is 93184, zero is 37888\n",
      "layer: 75, number of nonzero weight is 442566, zero is 147258\n",
      "layer: 78, number of nonzero weight is 226889, zero is 35255\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 196501, zero is 65643\n",
      "layer: 87, number of nonzero weight is 419931, zero is 169893\n",
      "layer: 90, number of nonzero weight is 230217, zero is 31927\n",
      "layer: 93, number of nonzero weight is 206676, zero is 55468\n",
      "layer: 96, number of nonzero weight is 416547, zero is 173277\n",
      "layer: 99, number of nonzero weight is 232419, zero is 29725\n",
      "layer: 102, number of nonzero weight is 194187, zero is 67957\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 233232, zero is 28912\n",
      "layer: 111, number of nonzero weight is 194246, zero is 67898\n",
      "layer: 114, number of nonzero weight is 416430, zero is 173394\n",
      "layer: 117, number of nonzero weight is 234952, zero is 27192\n",
      "layer: 120, number of nonzero weight is 185321, zero is 76823\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 235024, zero is 27120\n",
      "layer: 129, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 235017, zero is 27127\n",
      "layer: 138, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 235572, zero is 26572\n",
      "layer: 147, number of nonzero weight is 185326, zero is 76818\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 235745, zero is 26399\n",
      "layer: 156, number of nonzero weight is 191361, zero is 70783\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 238086, zero is 24058\n",
      "layer: 165, number of nonzero weight is 185339, zero is 76805\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 238452, zero is 23692\n",
      "layer: 174, number of nonzero weight is 186363, zero is 75781\n",
      "layer: 177, number of nonzero weight is 422910, zero is 166914\n",
      "layer: 180, number of nonzero weight is 240345, zero is 21799\n",
      "layer: 183, number of nonzero weight is 189438, zero is 72706\n",
      "layer: 186, number of nonzero weight is 418050, zero is 171774\n",
      "layer: 189, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 192, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 195, number of nonzero weight is 417996, zero is 171828\n",
      "layer: 198, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 201, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 210, number of nonzero weight is 187392, zero is 74752\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 219, number of nonzero weight is 188416, zero is 73728\n",
      "layer: 222, number of nonzero weight is 416376, zero is 173448\n",
      "layer: 225, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 228, number of nonzero weight is 189440, zero is 72704\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 237, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 240, number of nonzero weight is 416358, zero is 173466\n",
      "layer: 243, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 246, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 264, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 737280, zero is 311296\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1657503, zero is 701793\n",
      "layer: 309, number of nonzero weight is 955248, zero is 93328\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 294, 297, 300, 303, 306, 309]\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "mask Ready\n",
      "mask Done\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 9, number of nonzero weight is 11322, zero is 5062\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 21, number of nonzero weight is 11040, zero is 5344\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 25407, zero is 11457\n",
      "layer: 30, number of nonzero weight is 11184, zero is 5200\n",
      "layer: 33, number of nonzero weight is 23040, zero is 9728\n",
      "layer: 36, number of nonzero weight is 101016, zero is 46440\n",
      "layer: 39, number of nonzero weight is 45568, zero is 19968\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 45689, zero is 19847\n",
      "layer: 48, number of nonzero weight is 103437, zero is 44019\n",
      "layer: 51, number of nonzero weight is 44062, zero is 21474\n",
      "layer: 54, number of nonzero weight is 45968, zero is 19568\n",
      "layer: 57, number of nonzero weight is 100890, zero is 46566\n",
      "layer: 60, number of nonzero weight is 44832, zero is 20704\n",
      "layer: 63, number of nonzero weight is 46040, zero is 19496\n",
      "layer: 66, number of nonzero weight is 102636, zero is 44820\n",
      "layer: 69, number of nonzero weight is 45028, zero is 20508\n",
      "layer: 72, number of nonzero weight is 92160, zero is 38912\n",
      "layer: 75, number of nonzero weight is 406728, zero is 183096\n",
      "layer: 78, number of nonzero weight is 183198, zero is 78946\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 84, number of nonzero weight is 183711, zero is 78433\n",
      "layer: 87, number of nonzero weight is 413586, zero is 176238\n",
      "layer: 90, number of nonzero weight is 175960, zero is 86184\n",
      "layer: 93, number of nonzero weight is 183540, zero is 78604\n",
      "layer: 96, number of nonzero weight is 414243, zero is 175581\n",
      "layer: 99, number of nonzero weight is 176877, zero is 85267\n",
      "layer: 102, number of nonzero weight is 183984, zero is 78160\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 173824, zero is 88320\n",
      "layer: 111, number of nonzero weight is 184068, zero is 78076\n",
      "layer: 114, number of nonzero weight is 414126, zero is 175698\n",
      "layer: 117, number of nonzero weight is 173652, zero is 88492\n",
      "layer: 120, number of nonzero weight is 184297, zero is 77847\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 174128, zero is 88016\n",
      "layer: 129, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 176180, zero is 85964\n",
      "layer: 138, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 178688, zero is 83456\n",
      "layer: 147, number of nonzero weight is 184302, zero is 77842\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 178916, zero is 83228\n",
      "layer: 156, number of nonzero weight is 184193, zero is 77951\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 181348, zero is 80796\n",
      "layer: 165, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 180892, zero is 81252\n",
      "layer: 174, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 177, number of nonzero weight is 411390, zero is 178434\n",
      "layer: 180, number of nonzero weight is 180286, zero is 81858\n",
      "layer: 183, number of nonzero weight is 184318, zero is 77826\n",
      "layer: 186, number of nonzero weight is 413442, zero is 176382\n",
      "layer: 189, number of nonzero weight is 182220, zero is 79924\n",
      "layer: 192, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 195, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 198, number of nonzero weight is 182442, zero is 79702\n",
      "layer: 201, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 181880, zero is 80264\n",
      "layer: 210, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 179068, zero is 83076\n",
      "layer: 219, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 222, number of nonzero weight is 414072, zero is 175752\n",
      "layer: 225, number of nonzero weight is 179802, zero is 82342\n",
      "layer: 228, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 179448, zero is 82696\n",
      "layer: 237, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 240, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 243, number of nonzero weight is 180852, zero is 81292\n",
      "layer: 246, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 182032, zero is 80112\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 182488, zero is 79656\n",
      "layer: 264, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 181804, zero is 80340\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 182184, zero is 79960\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 732831, zero is 315745\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 732984, zero is 315592\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1652895, zero is 706401\n",
      "layer: 309, number of nonzero weight is 730864, zero is 317712\n",
      "Test: [0/196]\tTime 4.404 (4.404)\tLoss 0.9495 (0.9495)\tPrec@1 71.094 (71.094)\tPrec@5 95.312 (95.312)\n",
      " * Prec@1 55.114 Prec@5 80.548 Error@1 44.886\n",
      "\n",
      "\n",
      ">>>>> Accuracy_pruned:  55.114\n",
      " [resnet101] ::   3/ 10 ----- [[2020-10-03 16:58:35]] [Need: 24:39:50]\n",
      "Epoch: [3][0/5005]\tTime 28.433 (28.433)\tData 28.042 (28.042)\tLoss 1.8436 (1.8436)\tPrec@1 55.078 (55.078)\tPrec@5 82.812 (82.812)\n",
      "Epoch: [3][200/5005]\tTime 15.240 (2.416)\tData 14.872 (2.054)\tLoss 1.9375 (2.0859)\tPrec@1 55.078 (52.896)\tPrec@5 80.078 (76.792)\n",
      "Epoch: [3][400/5005]\tTime 14.609 (2.313)\tData 14.258 (1.952)\tLoss 2.0804 (2.0898)\tPrec@1 51.172 (52.617)\tPrec@5 75.000 (76.663)\n",
      "Epoch: [3][600/5005]\tTime 16.157 (2.279)\tData 15.806 (1.917)\tLoss 1.9009 (2.0936)\tPrec@1 57.812 (52.655)\tPrec@5 76.953 (76.531)\n",
      "Epoch: [3][800/5005]\tTime 14.067 (2.261)\tData 13.588 (1.900)\tLoss 2.4070 (2.0945)\tPrec@1 50.000 (52.724)\tPrec@5 72.266 (76.488)\n",
      "Epoch: [3][1000/5005]\tTime 12.966 (2.218)\tData 12.606 (1.857)\tLoss 2.2478 (2.0968)\tPrec@1 50.391 (52.592)\tPrec@5 72.656 (76.499)\n",
      "Epoch: [3][1200/5005]\tTime 13.662 (2.155)\tData 13.301 (1.794)\tLoss 2.2469 (2.0999)\tPrec@1 48.047 (52.524)\tPrec@5 73.438 (76.465)\n",
      "Epoch: [3][1400/5005]\tTime 13.158 (2.128)\tData 12.809 (1.767)\tLoss 2.0088 (2.1007)\tPrec@1 53.125 (52.513)\tPrec@5 78.125 (76.453)\n",
      "Epoch: [3][1600/5005]\tTime 12.846 (2.110)\tData 12.497 (1.749)\tLoss 2.1835 (2.1014)\tPrec@1 53.125 (52.493)\tPrec@5 75.391 (76.437)\n",
      "Epoch: [3][1800/5005]\tTime 9.635 (2.105)\tData 9.286 (1.744)\tLoss 2.0659 (2.1028)\tPrec@1 55.469 (52.452)\tPrec@5 77.734 (76.449)\n",
      "Epoch: [3][2000/5005]\tTime 15.692 (2.119)\tData 15.343 (1.758)\tLoss 1.9685 (2.1053)\tPrec@1 55.078 (52.375)\tPrec@5 77.344 (76.420)\n",
      "Epoch: [3][2200/5005]\tTime 14.895 (2.116)\tData 14.545 (1.755)\tLoss 2.2352 (2.1073)\tPrec@1 51.172 (52.320)\tPrec@5 71.875 (76.394)\n",
      "Epoch: [3][2400/5005]\tTime 3.936 (2.111)\tData 3.585 (1.750)\tLoss 2.2538 (2.1062)\tPrec@1 47.266 (52.359)\tPrec@5 73.828 (76.412)\n",
      "Epoch: [3][2600/5005]\tTime 5.758 (2.119)\tData 5.293 (1.759)\tLoss 2.1469 (2.1072)\tPrec@1 50.781 (52.361)\tPrec@5 75.781 (76.395)\n",
      "Epoch: [3][2800/5005]\tTime 13.460 (2.132)\tData 13.111 (1.771)\tLoss 2.0741 (2.1078)\tPrec@1 52.344 (52.361)\tPrec@5 77.344 (76.379)\n",
      "Epoch: [3][3000/5005]\tTime 16.075 (2.135)\tData 15.725 (1.775)\tLoss 2.1804 (2.1087)\tPrec@1 54.297 (52.351)\tPrec@5 73.828 (76.367)\n",
      "Epoch: [3][3200/5005]\tTime 14.296 (2.136)\tData 13.946 (1.775)\tLoss 2.0812 (2.1092)\tPrec@1 52.344 (52.340)\tPrec@5 76.953 (76.357)\n",
      "Epoch: [3][3400/5005]\tTime 14.127 (2.137)\tData 13.763 (1.777)\tLoss 2.0904 (2.1105)\tPrec@1 55.078 (52.325)\tPrec@5 75.000 (76.346)\n",
      "Epoch: [3][3600/5005]\tTime 9.122 (2.149)\tData 8.756 (1.789)\tLoss 2.2697 (2.1105)\tPrec@1 48.828 (52.334)\tPrec@5 72.656 (76.337)\n",
      "Epoch: [3][3800/5005]\tTime 14.571 (2.171)\tData 14.209 (1.810)\tLoss 2.0226 (2.1113)\tPrec@1 53.516 (52.321)\tPrec@5 75.781 (76.326)\n",
      "Epoch: [3][4000/5005]\tTime 14.276 (2.186)\tData 13.926 (1.825)\tLoss 2.1142 (2.1120)\tPrec@1 51.172 (52.312)\tPrec@5 75.000 (76.321)\n",
      "Epoch: [3][4200/5005]\tTime 8.047 (2.207)\tData 7.697 (1.846)\tLoss 2.0785 (2.1132)\tPrec@1 51.562 (52.293)\tPrec@5 78.125 (76.297)\n",
      "Epoch: [3][4400/5005]\tTime 10.792 (2.231)\tData 10.326 (1.871)\tLoss 1.9984 (2.1132)\tPrec@1 54.297 (52.290)\tPrec@5 77.734 (76.294)\n",
      "Epoch: [3][4600/5005]\tTime 6.512 (2.254)\tData 6.160 (1.894)\tLoss 2.3066 (2.1138)\tPrec@1 47.656 (52.274)\tPrec@5 74.609 (76.292)\n",
      "Epoch: [3][4800/5005]\tTime 0.349 (2.272)\tData 0.000 (1.912)\tLoss 2.1075 (2.1138)\tPrec@1 52.734 (52.269)\tPrec@5 76.172 (76.294)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5000/5005]\tTime 0.349 (2.288)\tData 0.000 (1.927)\tLoss 1.9631 (2.1135)\tPrec@1 53.516 (52.276)\tPrec@5 78.906 (76.295)\n",
      "Test: [0/196]\tTime 8.934 (8.934)\tLoss 1.3313 (1.3313)\tPrec@1 66.797 (66.797)\tPrec@5 88.672 (88.672)\n",
      " * Prec@1 54.558 Prec@5 79.542 Error@1 45.442\n",
      "\n",
      "\n",
      ">>>>> Accuracy_model:  54.558\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 26325, zero is 10539\n",
      "layer: 9, number of nonzero weight is 13774, zero is 2610\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 26253, zero is 10611\n",
      "layer: 21, number of nonzero weight is 14204, zero is 2180\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 27135, zero is 9729\n",
      "layer: 30, number of nonzero weight is 15168, zero is 1216\n",
      "layer: 33, number of nonzero weight is 23296, zero is 9472\n",
      "layer: 36, number of nonzero weight is 121698, zero is 25758\n",
      "layer: 39, number of nonzero weight is 55904, zero is 9632\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 51001, zero is 14535\n",
      "layer: 48, number of nonzero weight is 106407, zero is 41049\n",
      "layer: 51, number of nonzero weight is 57577, zero is 7959\n",
      "layer: 54, number of nonzero weight is 49468, zero is 16068\n",
      "layer: 57, number of nonzero weight is 112410, zero is 35046\n",
      "layer: 60, number of nonzero weight is 60452, zero is 5084\n",
      "layer: 63, number of nonzero weight is 50616, zero is 14920\n",
      "layer: 66, number of nonzero weight is 108135, zero is 39321\n",
      "layer: 69, number of nonzero weight is 60487, zero is 5049\n",
      "layer: 72, number of nonzero weight is 93184, zero is 37888\n",
      "layer: 75, number of nonzero weight is 442566, zero is 147258\n",
      "layer: 78, number of nonzero weight is 226889, zero is 35255\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 196501, zero is 65643\n",
      "layer: 87, number of nonzero weight is 419931, zero is 169893\n",
      "layer: 90, number of nonzero weight is 230217, zero is 31927\n",
      "layer: 93, number of nonzero weight is 206676, zero is 55468\n",
      "layer: 96, number of nonzero weight is 416547, zero is 173277\n",
      "layer: 99, number of nonzero weight is 232419, zero is 29725\n",
      "layer: 102, number of nonzero weight is 194187, zero is 67957\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 233232, zero is 28912\n",
      "layer: 111, number of nonzero weight is 194246, zero is 67898\n",
      "layer: 114, number of nonzero weight is 416430, zero is 173394\n",
      "layer: 117, number of nonzero weight is 234952, zero is 27192\n",
      "layer: 120, number of nonzero weight is 185321, zero is 76823\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 235024, zero is 27120\n",
      "layer: 129, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 235017, zero is 27127\n",
      "layer: 138, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 235572, zero is 26572\n",
      "layer: 147, number of nonzero weight is 185326, zero is 76818\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 235745, zero is 26399\n",
      "layer: 156, number of nonzero weight is 191361, zero is 70783\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 238086, zero is 24058\n",
      "layer: 165, number of nonzero weight is 185339, zero is 76805\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 238452, zero is 23692\n",
      "layer: 174, number of nonzero weight is 186363, zero is 75781\n",
      "layer: 177, number of nonzero weight is 422910, zero is 166914\n",
      "layer: 180, number of nonzero weight is 240345, zero is 21799\n",
      "layer: 183, number of nonzero weight is 189438, zero is 72706\n",
      "layer: 186, number of nonzero weight is 418050, zero is 171774\n",
      "layer: 189, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 192, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 195, number of nonzero weight is 417996, zero is 171828\n",
      "layer: 198, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 201, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 210, number of nonzero weight is 187392, zero is 74752\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 219, number of nonzero weight is 188416, zero is 73728\n",
      "layer: 222, number of nonzero weight is 416376, zero is 173448\n",
      "layer: 225, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 228, number of nonzero weight is 189440, zero is 72704\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 237, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 240, number of nonzero weight is 416358, zero is 173466\n",
      "layer: 243, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 246, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 264, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 737280, zero is 311296\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1657503, zero is 701793\n",
      "layer: 309, number of nonzero weight is 955248, zero is 93328\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 294, 297, 300, 303, 306, 309]\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "mask Ready\n",
      "mask Done\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 9, number of nonzero weight is 11286, zero is 5098\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 21, number of nonzero weight is 11020, zero is 5364\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 25407, zero is 11457\n",
      "layer: 30, number of nonzero weight is 11088, zero is 5296\n",
      "layer: 33, number of nonzero weight is 23040, zero is 9728\n",
      "layer: 36, number of nonzero weight is 100017, zero is 47439\n",
      "layer: 39, number of nonzero weight is 45584, zero is 19952\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 45689, zero is 19847\n",
      "layer: 48, number of nonzero weight is 103437, zero is 44019\n",
      "layer: 51, number of nonzero weight is 44132, zero is 21404\n",
      "layer: 54, number of nonzero weight is 45968, zero is 19568\n",
      "layer: 57, number of nonzero weight is 100890, zero is 46566\n",
      "layer: 60, number of nonzero weight is 44776, zero is 20760\n",
      "layer: 63, number of nonzero weight is 46040, zero is 19496\n",
      "layer: 66, number of nonzero weight is 102636, zero is 44820\n",
      "layer: 69, number of nonzero weight is 44962, zero is 20574\n",
      "layer: 72, number of nonzero weight is 92160, zero is 38912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 75, number of nonzero weight is 406728, zero is 183096\n",
      "layer: 78, number of nonzero weight is 183139, zero is 79005\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 183711, zero is 78433\n",
      "layer: 87, number of nonzero weight is 413586, zero is 176238\n",
      "layer: 90, number of nonzero weight is 175668, zero is 86476\n",
      "layer: 93, number of nonzero weight is 183488, zero is 78656\n",
      "layer: 96, number of nonzero weight is 414243, zero is 175581\n",
      "layer: 99, number of nonzero weight is 176577, zero is 85567\n",
      "layer: 102, number of nonzero weight is 183984, zero is 78160\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 173444, zero is 88700\n",
      "layer: 111, number of nonzero weight is 184068, zero is 78076\n",
      "layer: 114, number of nonzero weight is 414126, zero is 175698\n",
      "layer: 117, number of nonzero weight is 173802, zero is 88342\n",
      "layer: 120, number of nonzero weight is 184297, zero is 77847\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 173292, zero is 88852\n",
      "layer: 129, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 175648, zero is 86496\n",
      "layer: 138, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 178536, zero is 83608\n",
      "layer: 147, number of nonzero weight is 184302, zero is 77842\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 178460, zero is 83684\n",
      "layer: 156, number of nonzero weight is 184193, zero is 77951\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 181196, zero is 80948\n",
      "layer: 165, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 180664, zero is 81480\n",
      "layer: 174, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 177, number of nonzero weight is 411390, zero is 178434\n",
      "layer: 180, number of nonzero weight is 180144, zero is 82000\n",
      "layer: 183, number of nonzero weight is 184318, zero is 77826\n",
      "layer: 186, number of nonzero weight is 413442, zero is 176382\n",
      "layer: 189, number of nonzero weight is 181998, zero is 80146\n",
      "layer: 192, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 195, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 198, number of nonzero weight is 182442, zero is 79702\n",
      "layer: 201, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 181804, zero is 80340\n",
      "layer: 210, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 178992, zero is 83152\n",
      "layer: 219, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 222, number of nonzero weight is 414072, zero is 175752\n",
      "layer: 225, number of nonzero weight is 179652, zero is 82492\n",
      "layer: 228, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 178992, zero is 83152\n",
      "layer: 237, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 240, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 243, number of nonzero weight is 180777, zero is 81367\n",
      "layer: 246, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 182032, zero is 80112\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 182184, zero is 79960\n",
      "layer: 264, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 181804, zero is 80340\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 182108, zero is 80036\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 732831, zero is 315745\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 732984, zero is 315592\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1652895, zero is 706401\n",
      "layer: 309, number of nonzero weight is 730864, zero is 317712\n",
      "Test: [0/196]\tTime 5.685 (5.685)\tLoss 1.3090 (1.3090)\tPrec@1 67.578 (67.578)\tPrec@5 88.281 (88.281)\n",
      " * Prec@1 54.294 Prec@5 79.378 Error@1 45.706\n",
      "\n",
      "\n",
      ">>>>> Accuracy_pruned:  54.294\n",
      " [resnet101] ::   4/ 10 ----- [[2020-10-03 20:13:34]] [Need: 19:29:52]\n",
      "Epoch: [4][0/5005]\tTime 30.131 (30.131)\tData 29.732 (29.732)\tLoss 2.2496 (2.2496)\tPrec@1 50.781 (50.781)\tPrec@5 71.875 (71.875)\n",
      "Epoch: [4][200/5005]\tTime 19.142 (2.726)\tData 18.792 (2.364)\tLoss 1.8775 (2.0807)\tPrec@1 57.422 (52.958)\tPrec@5 78.516 (76.671)\n",
      "Epoch: [4][400/5005]\tTime 20.399 (2.672)\tData 20.050 (2.311)\tLoss 2.0976 (2.0820)\tPrec@1 52.734 (52.827)\tPrec@5 75.391 (76.701)\n",
      "Epoch: [4][600/5005]\tTime 19.670 (2.831)\tData 19.300 (2.469)\tLoss 2.2808 (2.0831)\tPrec@1 48.828 (52.778)\tPrec@5 74.219 (76.749)\n",
      "Epoch: [4][800/5005]\tTime 24.407 (2.907)\tData 24.058 (2.546)\tLoss 1.8574 (2.0839)\tPrec@1 57.812 (52.715)\tPrec@5 80.469 (76.727)\n",
      "Epoch: [4][1000/5005]\tTime 19.280 (2.902)\tData 18.914 (2.541)\tLoss 1.9063 (2.0861)\tPrec@1 58.984 (52.692)\tPrec@5 80.078 (76.658)\n",
      "Epoch: [4][1200/5005]\tTime 19.402 (2.907)\tData 19.052 (2.546)\tLoss 2.1392 (2.0883)\tPrec@1 52.344 (52.658)\tPrec@5 74.609 (76.656)\n",
      "Epoch: [4][1400/5005]\tTime 24.235 (2.950)\tData 23.883 (2.588)\tLoss 2.1749 (2.0892)\tPrec@1 51.172 (52.623)\tPrec@5 75.391 (76.656)\n",
      "Epoch: [4][1600/5005]\tTime 20.058 (2.981)\tData 19.695 (2.620)\tLoss 2.0828 (2.0910)\tPrec@1 52.734 (52.626)\tPrec@5 77.344 (76.628)\n",
      "Epoch: [4][1800/5005]\tTime 15.122 (2.989)\tData 14.772 (2.627)\tLoss 2.0139 (2.0945)\tPrec@1 55.859 (52.579)\tPrec@5 77.344 (76.564)\n",
      "Epoch: [4][2000/5005]\tTime 13.970 (2.979)\tData 13.620 (2.618)\tLoss 1.9663 (2.0958)\tPrec@1 56.641 (52.574)\tPrec@5 78.516 (76.522)\n",
      "Epoch: [4][2200/5005]\tTime 18.045 (2.991)\tData 17.694 (2.630)\tLoss 2.2471 (2.0963)\tPrec@1 49.219 (52.552)\tPrec@5 73.438 (76.516)\n",
      "Epoch: [4][2400/5005]\tTime 15.621 (3.011)\tData 15.254 (2.650)\tLoss 1.9445 (2.0965)\tPrec@1 58.203 (52.550)\tPrec@5 76.562 (76.520)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][2600/5005]\tTime 13.140 (3.027)\tData 12.789 (2.666)\tLoss 1.9747 (2.0976)\tPrec@1 52.344 (52.546)\tPrec@5 78.516 (76.511)\n",
      "Epoch: [4][2800/5005]\tTime 13.315 (3.041)\tData 12.966 (2.680)\tLoss 2.0039 (2.0986)\tPrec@1 52.344 (52.543)\tPrec@5 77.734 (76.496)\n",
      "Epoch: [4][3000/5005]\tTime 19.484 (3.056)\tData 19.134 (2.695)\tLoss 2.0735 (2.0996)\tPrec@1 51.562 (52.532)\tPrec@5 73.047 (76.475)\n",
      "Epoch: [4][3200/5005]\tTime 15.081 (3.072)\tData 14.729 (2.711)\tLoss 2.0794 (2.1018)\tPrec@1 48.438 (52.489)\tPrec@5 77.734 (76.440)\n",
      "Epoch: [4][3400/5005]\tTime 15.955 (3.088)\tData 15.590 (2.727)\tLoss 2.2244 (2.1031)\tPrec@1 50.000 (52.468)\tPrec@5 73.438 (76.424)\n",
      "Epoch: [4][3600/5005]\tTime 13.496 (3.099)\tData 13.129 (2.738)\tLoss 1.9251 (2.1036)\tPrec@1 51.953 (52.450)\tPrec@5 79.688 (76.425)\n",
      "Epoch: [4][3800/5005]\tTime 9.470 (3.047)\tData 9.100 (2.686)\tLoss 2.3634 (2.1045)\tPrec@1 46.875 (52.435)\tPrec@5 71.875 (76.418)\n",
      "Epoch: [4][4000/5005]\tTime 12.165 (3.017)\tData 11.815 (2.656)\tLoss 2.0498 (2.1040)\tPrec@1 55.859 (52.450)\tPrec@5 76.562 (76.426)\n",
      "Epoch: [4][4200/5005]\tTime 12.554 (2.990)\tData 12.188 (2.629)\tLoss 2.0157 (2.1042)\tPrec@1 52.734 (52.460)\tPrec@5 78.516 (76.429)\n",
      "Epoch: [4][4400/5005]\tTime 7.608 (2.968)\tData 7.246 (2.607)\tLoss 2.0405 (2.1057)\tPrec@1 50.391 (52.440)\tPrec@5 77.344 (76.400)\n",
      "Epoch: [4][4600/5005]\tTime 6.037 (2.960)\tData 5.670 (2.599)\tLoss 2.0302 (2.1066)\tPrec@1 52.734 (52.421)\tPrec@5 78.516 (76.390)\n",
      "Epoch: [4][4800/5005]\tTime 9.165 (2.947)\tData 8.708 (2.586)\tLoss 2.2030 (2.1071)\tPrec@1 52.734 (52.409)\tPrec@5 74.609 (76.379)\n",
      "Epoch: [4][5000/5005]\tTime 5.774 (2.947)\tData 5.423 (2.586)\tLoss 2.2300 (2.1073)\tPrec@1 48.828 (52.398)\tPrec@5 73.438 (76.377)\n",
      "Test: [0/196]\tTime 9.942 (9.942)\tLoss 1.0794 (1.0794)\tPrec@1 70.312 (70.312)\tPrec@5 91.406 (91.406)\n",
      " * Prec@1 55.046 Prec@5 80.420 Error@1 44.954\n",
      "\n",
      "\n",
      ">>>>> Accuracy_model:  55.046\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 26325, zero is 10539\n",
      "layer: 9, number of nonzero weight is 13774, zero is 2610\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 26253, zero is 10611\n",
      "layer: 21, number of nonzero weight is 14204, zero is 2180\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 27135, zero is 9729\n",
      "layer: 30, number of nonzero weight is 15168, zero is 1216\n",
      "layer: 33, number of nonzero weight is 23296, zero is 9472\n",
      "layer: 36, number of nonzero weight is 121698, zero is 25758\n",
      "layer: 39, number of nonzero weight is 55904, zero is 9632\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 51001, zero is 14535\n",
      "layer: 48, number of nonzero weight is 106407, zero is 41049\n",
      "layer: 51, number of nonzero weight is 57577, zero is 7959\n",
      "layer: 54, number of nonzero weight is 49468, zero is 16068\n",
      "layer: 57, number of nonzero weight is 112410, zero is 35046\n",
      "layer: 60, number of nonzero weight is 60452, zero is 5084\n",
      "layer: 63, number of nonzero weight is 50616, zero is 14920\n",
      "layer: 66, number of nonzero weight is 108135, zero is 39321\n",
      "layer: 69, number of nonzero weight is 60487, zero is 5049\n",
      "layer: 72, number of nonzero weight is 93184, zero is 37888\n",
      "layer: 75, number of nonzero weight is 442566, zero is 147258\n",
      "layer: 78, number of nonzero weight is 226889, zero is 35255\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 196501, zero is 65643\n",
      "layer: 87, number of nonzero weight is 419931, zero is 169893\n",
      "layer: 90, number of nonzero weight is 230217, zero is 31927\n",
      "layer: 93, number of nonzero weight is 206676, zero is 55468\n",
      "layer: 96, number of nonzero weight is 416547, zero is 173277\n",
      "layer: 99, number of nonzero weight is 232419, zero is 29725\n",
      "layer: 102, number of nonzero weight is 194187, zero is 67957\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 233232, zero is 28912\n",
      "layer: 111, number of nonzero weight is 194247, zero is 67897\n",
      "layer: 114, number of nonzero weight is 416430, zero is 173394\n",
      "layer: 117, number of nonzero weight is 234952, zero is 27192\n",
      "layer: 120, number of nonzero weight is 185321, zero is 76823\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 235024, zero is 27120\n",
      "layer: 129, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 235017, zero is 27127\n",
      "layer: 138, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 235572, zero is 26572\n",
      "layer: 147, number of nonzero weight is 185326, zero is 76818\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 235745, zero is 26399\n",
      "layer: 156, number of nonzero weight is 191361, zero is 70783\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 238086, zero is 24058\n",
      "layer: 165, number of nonzero weight is 185339, zero is 76805\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 238452, zero is 23692\n",
      "layer: 174, number of nonzero weight is 186363, zero is 75781\n",
      "layer: 177, number of nonzero weight is 422910, zero is 166914\n",
      "layer: 180, number of nonzero weight is 240345, zero is 21799\n",
      "layer: 183, number of nonzero weight is 189438, zero is 72706\n",
      "layer: 186, number of nonzero weight is 418050, zero is 171774\n",
      "layer: 189, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 192, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 195, number of nonzero weight is 417996, zero is 171828\n",
      "layer: 198, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 201, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 210, number of nonzero weight is 187392, zero is 74752\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 219, number of nonzero weight is 188416, zero is 73728\n",
      "layer: 222, number of nonzero weight is 416376, zero is 173448\n",
      "layer: 225, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 228, number of nonzero weight is 189440, zero is 72704\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 237, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 240, number of nonzero weight is 416358, zero is 173466\n",
      "layer: 243, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 246, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 264, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 737280, zero is 311296\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1657503, zero is 701793\n",
      "layer: 309, number of nonzero weight is 955248, zero is 93328\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 294, 297, 300, 303, 306, 309]\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "mask Ready\n",
      "mask Done\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 9, number of nonzero weight is 11268, zero is 5116\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 21, number of nonzero weight is 11040, zero is 5344\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 25407, zero is 11457\n",
      "layer: 30, number of nonzero weight is 11216, zero is 5168\n",
      "layer: 33, number of nonzero weight is 23040, zero is 9728\n",
      "layer: 36, number of nonzero weight is 100017, zero is 47439\n",
      "layer: 39, number of nonzero weight is 45536, zero is 20000\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 45689, zero is 19847\n",
      "layer: 48, number of nonzero weight is 103437, zero is 44019\n",
      "layer: 51, number of nonzero weight is 44132, zero is 21404\n",
      "layer: 54, number of nonzero weight is 45968, zero is 19568\n",
      "layer: 57, number of nonzero weight is 100890, zero is 46566\n",
      "layer: 60, number of nonzero weight is 44748, zero is 20788\n",
      "layer: 63, number of nonzero weight is 46040, zero is 19496\n",
      "layer: 66, number of nonzero weight is 102636, zero is 44820\n",
      "layer: 69, number of nonzero weight is 44962, zero is 20574\n",
      "layer: 72, number of nonzero weight is 92160, zero is 38912\n",
      "layer: 75, number of nonzero weight is 406728, zero is 183096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 78, number of nonzero weight is 183080, zero is 79064\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 183711, zero is 78433\n",
      "layer: 87, number of nonzero weight is 413586, zero is 176238\n",
      "layer: 90, number of nonzero weight is 175668, zero is 86476\n",
      "layer: 93, number of nonzero weight is 183488, zero is 78656\n",
      "layer: 96, number of nonzero weight is 414243, zero is 175581\n",
      "layer: 99, number of nonzero weight is 176502, zero is 85642\n",
      "layer: 102, number of nonzero weight is 183984, zero is 78160\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 172912, zero is 89232\n",
      "layer: 111, number of nonzero weight is 184069, zero is 78075\n",
      "layer: 114, number of nonzero weight is 414126, zero is 175698\n",
      "layer: 117, number of nonzero weight is 173127, zero is 89017\n",
      "layer: 120, number of nonzero weight is 184297, zero is 77847\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 173900, zero is 88244\n",
      "layer: 129, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 175572, zero is 86572\n",
      "layer: 138, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 178308, zero is 83836\n",
      "layer: 147, number of nonzero weight is 184302, zero is 77842\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 177852, zero is 84292\n",
      "layer: 156, number of nonzero weight is 184193, zero is 77951\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 180968, zero is 81176\n",
      "layer: 165, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 180664, zero is 81480\n",
      "layer: 174, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 177, number of nonzero weight is 411390, zero is 178434\n",
      "layer: 180, number of nonzero weight is 179931, zero is 82213\n",
      "layer: 183, number of nonzero weight is 184318, zero is 77826\n",
      "layer: 186, number of nonzero weight is 413442, zero is 176382\n",
      "layer: 189, number of nonzero weight is 181850, zero is 80294\n",
      "layer: 192, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 195, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 198, number of nonzero weight is 182368, zero is 79776\n",
      "layer: 201, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 181652, zero is 80492\n",
      "layer: 210, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 178764, zero is 83380\n",
      "layer: 219, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 222, number of nonzero weight is 414072, zero is 175752\n",
      "layer: 225, number of nonzero weight is 179277, zero is 82867\n",
      "layer: 228, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 178916, zero is 83228\n",
      "layer: 237, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 240, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 243, number of nonzero weight is 180552, zero is 81592\n",
      "layer: 246, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 182032, zero is 80112\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 182108, zero is 80036\n",
      "layer: 264, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 181804, zero is 80340\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 181956, zero is 80188\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 732831, zero is 315745\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 732984, zero is 315592\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1652895, zero is 706401\n",
      "layer: 309, number of nonzero weight is 730864, zero is 317712\n",
      "Test: [0/196]\tTime 8.191 (8.191)\tLoss 1.0722 (1.0722)\tPrec@1 70.703 (70.703)\tPrec@5 92.188 (92.188)\n",
      " * Prec@1 55.078 Prec@5 80.430 Error@1 44.922\n",
      "\n",
      "\n",
      ">>>>> Accuracy_pruned:  55.078\n",
      " [resnet101] ::   5/ 10 ----- [[2020-10-04 00:25:45]] [Need: 21:00:59]\n",
      "Epoch: [5][0/5005]\tTime 27.380 (27.380)\tData 26.998 (26.998)\tLoss 2.0114 (2.0114)\tPrec@1 55.859 (55.859)\tPrec@5 76.562 (76.562)\n",
      "Epoch: [5][200/5005]\tTime 10.791 (2.929)\tData 10.333 (2.567)\tLoss 2.2514 (2.0679)\tPrec@1 50.000 (53.226)\tPrec@5 75.781 (77.249)\n",
      "Epoch: [5][400/5005]\tTime 7.217 (2.849)\tData 6.867 (2.488)\tLoss 2.0619 (2.0702)\tPrec@1 51.562 (53.053)\tPrec@5 74.219 (77.178)\n",
      "Epoch: [5][600/5005]\tTime 1.498 (2.841)\tData 1.147 (2.479)\tLoss 2.1091 (2.0724)\tPrec@1 56.250 (52.971)\tPrec@5 75.781 (77.036)\n",
      "Epoch: [5][800/5005]\tTime 0.352 (2.812)\tData 0.000 (2.451)\tLoss 2.0932 (2.0783)\tPrec@1 53.516 (52.819)\tPrec@5 77.344 (76.920)\n",
      "Epoch: [5][1000/5005]\tTime 0.351 (2.765)\tData 0.000 (2.403)\tLoss 1.9625 (2.0866)\tPrec@1 51.953 (52.738)\tPrec@5 75.391 (76.780)\n",
      "Epoch: [5][1200/5005]\tTime 0.348 (2.727)\tData 0.000 (2.366)\tLoss 2.0365 (2.0861)\tPrec@1 52.344 (52.770)\tPrec@5 75.781 (76.760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][1400/5005]\tTime 0.349 (2.701)\tData 0.000 (2.339)\tLoss 2.1927 (2.0886)\tPrec@1 51.172 (52.751)\tPrec@5 74.609 (76.737)\n",
      "Epoch: [5][1600/5005]\tTime 0.350 (2.725)\tData 0.000 (2.363)\tLoss 2.2604 (2.0886)\tPrec@1 51.953 (52.773)\tPrec@5 73.047 (76.741)\n",
      "Epoch: [5][1800/5005]\tTime 0.350 (2.723)\tData 0.000 (2.361)\tLoss 2.1041 (2.0895)\tPrec@1 52.734 (52.753)\tPrec@5 77.734 (76.724)\n",
      "Epoch: [5][2000/5005]\tTime 0.471 (2.721)\tData 0.000 (2.360)\tLoss 2.0952 (2.0911)\tPrec@1 53.516 (52.743)\tPrec@5 73.438 (76.694)\n",
      "Epoch: [5][2200/5005]\tTime 0.351 (2.689)\tData 0.000 (2.328)\tLoss 2.0733 (2.0910)\tPrec@1 50.391 (52.732)\tPrec@5 76.953 (76.696)\n",
      "Epoch: [5][2400/5005]\tTime 0.350 (2.701)\tData 0.000 (2.340)\tLoss 1.9547 (2.0918)\tPrec@1 57.812 (52.699)\tPrec@5 76.953 (76.684)\n",
      "Epoch: [5][2600/5005]\tTime 0.350 (2.687)\tData 0.000 (2.326)\tLoss 2.3733 (2.0939)\tPrec@1 47.266 (52.645)\tPrec@5 75.391 (76.650)\n",
      "Epoch: [5][2800/5005]\tTime 0.348 (2.689)\tData 0.000 (2.328)\tLoss 2.0749 (2.0950)\tPrec@1 53.516 (52.605)\tPrec@5 73.438 (76.636)\n",
      "Epoch: [5][3000/5005]\tTime 0.350 (2.693)\tData 0.000 (2.332)\tLoss 2.0517 (2.0963)\tPrec@1 52.344 (52.572)\tPrec@5 77.344 (76.608)\n",
      "Epoch: [5][3200/5005]\tTime 0.349 (2.697)\tData 0.000 (2.336)\tLoss 2.0314 (2.0972)\tPrec@1 53.906 (52.560)\tPrec@5 76.562 (76.591)\n",
      "Epoch: [5][3400/5005]\tTime 0.349 (2.703)\tData 0.000 (2.341)\tLoss 2.1721 (2.0975)\tPrec@1 53.516 (52.560)\tPrec@5 73.047 (76.582)\n",
      "Epoch: [5][3600/5005]\tTime 0.350 (2.712)\tData 0.000 (2.350)\tLoss 2.0210 (2.0973)\tPrec@1 52.344 (52.561)\tPrec@5 76.953 (76.584)\n",
      "Epoch: [5][3800/5005]\tTime 0.472 (2.690)\tData 0.000 (2.329)\tLoss 1.9294 (2.0974)\tPrec@1 56.641 (52.548)\tPrec@5 75.391 (76.586)\n",
      "Epoch: [5][4000/5005]\tTime 0.350 (2.652)\tData 0.000 (2.291)\tLoss 2.1774 (2.0981)\tPrec@1 53.906 (52.526)\tPrec@5 75.000 (76.579)\n",
      "Epoch: [5][4200/5005]\tTime 0.350 (2.614)\tData 0.000 (2.253)\tLoss 2.2594 (2.0988)\tPrec@1 48.047 (52.509)\tPrec@5 75.391 (76.563)\n",
      "Epoch: [5][4400/5005]\tTime 0.349 (2.582)\tData 0.000 (2.221)\tLoss 1.9222 (2.0988)\tPrec@1 56.641 (52.511)\tPrec@5 78.516 (76.552)\n",
      "Epoch: [5][4600/5005]\tTime 0.352 (2.556)\tData 0.000 (2.194)\tLoss 2.3448 (2.0993)\tPrec@1 46.875 (52.508)\tPrec@5 73.438 (76.544)\n",
      "Epoch: [5][4800/5005]\tTime 0.369 (2.523)\tData 0.001 (2.161)\tLoss 2.2986 (2.1006)\tPrec@1 50.000 (52.491)\tPrec@5 73.828 (76.528)\n",
      "Epoch: [5][5000/5005]\tTime 0.350 (2.512)\tData 0.000 (2.151)\tLoss 2.1087 (2.1020)\tPrec@1 53.125 (52.469)\tPrec@5 75.391 (76.506)\n",
      "Test: [0/196]\tTime 11.466 (11.466)\tLoss 0.8092 (0.8092)\tPrec@1 75.391 (75.391)\tPrec@5 97.656 (97.656)\n",
      " * Prec@1 55.320 Prec@5 80.492 Error@1 44.680\n",
      "\n",
      "\n",
      ">>>>> Accuracy_model:  55.32\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 26325, zero is 10539\n",
      "layer: 9, number of nonzero weight is 13774, zero is 2610\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 26253, zero is 10611\n",
      "layer: 21, number of nonzero weight is 14204, zero is 2180\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 27135, zero is 9729\n",
      "layer: 30, number of nonzero weight is 15168, zero is 1216\n",
      "layer: 33, number of nonzero weight is 23296, zero is 9472\n",
      "layer: 36, number of nonzero weight is 121698, zero is 25758\n",
      "layer: 39, number of nonzero weight is 55904, zero is 9632\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 51001, zero is 14535\n",
      "layer: 48, number of nonzero weight is 106407, zero is 41049\n",
      "layer: 51, number of nonzero weight is 57577, zero is 7959\n",
      "layer: 54, number of nonzero weight is 49468, zero is 16068\n",
      "layer: 57, number of nonzero weight is 112410, zero is 35046\n",
      "layer: 60, number of nonzero weight is 60452, zero is 5084\n",
      "layer: 63, number of nonzero weight is 50616, zero is 14920\n",
      "layer: 66, number of nonzero weight is 108135, zero is 39321\n",
      "layer: 69, number of nonzero weight is 60487, zero is 5049\n",
      "layer: 72, number of nonzero weight is 93184, zero is 37888\n",
      "layer: 75, number of nonzero weight is 442566, zero is 147258\n",
      "layer: 78, number of nonzero weight is 226889, zero is 35255\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 196501, zero is 65643\n",
      "layer: 87, number of nonzero weight is 419931, zero is 169893\n",
      "layer: 90, number of nonzero weight is 230217, zero is 31927\n",
      "layer: 93, number of nonzero weight is 206676, zero is 55468\n",
      "layer: 96, number of nonzero weight is 416547, zero is 173277\n",
      "layer: 99, number of nonzero weight is 232419, zero is 29725\n",
      "layer: 102, number of nonzero weight is 194187, zero is 67957\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 233232, zero is 28912\n",
      "layer: 111, number of nonzero weight is 194248, zero is 67896\n",
      "layer: 114, number of nonzero weight is 416430, zero is 173394\n",
      "layer: 117, number of nonzero weight is 234952, zero is 27192\n",
      "layer: 120, number of nonzero weight is 185321, zero is 76823\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 235024, zero is 27120\n",
      "layer: 129, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 235017, zero is 27127\n",
      "layer: 138, number of nonzero weight is 185323, zero is 76821\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 235572, zero is 26572\n",
      "layer: 147, number of nonzero weight is 185326, zero is 76818\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 235745, zero is 26399\n",
      "layer: 156, number of nonzero weight is 191361, zero is 70783\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 238086, zero is 24058\n",
      "layer: 165, number of nonzero weight is 185339, zero is 76805\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 238452, zero is 23692\n",
      "layer: 174, number of nonzero weight is 186363, zero is 75781\n",
      "layer: 177, number of nonzero weight is 422910, zero is 166914\n",
      "layer: 180, number of nonzero weight is 240345, zero is 21799\n",
      "layer: 183, number of nonzero weight is 189438, zero is 72706\n",
      "layer: 186, number of nonzero weight is 418050, zero is 171774\n",
      "layer: 189, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 192, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 195, number of nonzero weight is 417996, zero is 171828\n",
      "layer: 198, number of nonzero weight is 239426, zero is 22718\n",
      "layer: 201, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 210, number of nonzero weight is 187392, zero is 74752\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 219, number of nonzero weight is 188416, zero is 73728\n",
      "layer: 222, number of nonzero weight is 416376, zero is 173448\n",
      "layer: 225, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 228, number of nonzero weight is 189440, zero is 72704\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 237, number of nonzero weight is 186368, zero is 75776\n",
      "layer: 240, number of nonzero weight is 416358, zero is 173466\n",
      "layer: 243, number of nonzero weight is 239119, zero is 23025\n",
      "layer: 246, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 264, number of nonzero weight is 185344, zero is 76800\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 238812, zero is 23332\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 294, number of nonzero weight is 737280, zero is 311296\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 954634, zero is 93942\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1657503, zero is 701793\n",
      "layer: 309, number of nonzero weight is 955248, zero is 93328\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 291, 294, 297, 300, 303, 306, 309]\n",
      "[0, 3, 6, 9, 15, 18, 21, 24, 27, 30, 33, 36, 39, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 84, 87, 90, 93, 96, 99, 102, 105, 108, 111, 114, 117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153, 156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270, 273, 276, 279, 282, 285, 288, 294, 297, 300, 303, 306, 309]\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "filter codebook done\n",
      "mask Ready\n",
      "mask Done\n",
      "layer: 0, number of nonzero weight is 6615, zero is 2793\n",
      "layer: 3, number of nonzero weight is 2880, zero is 1216\n",
      "layer: 6, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 9, number of nonzero weight is 11268, zero is 5116\n",
      "layer: 12, number of nonzero weight is 16384, zero is 0\n",
      "layer: 15, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 18, number of nonzero weight is 25920, zero is 10944\n",
      "layer: 21, number of nonzero weight is 11060, zero is 5324\n",
      "layer: 24, number of nonzero weight is 11520, zero is 4864\n",
      "layer: 27, number of nonzero weight is 25578, zero is 11286\n",
      "layer: 30, number of nonzero weight is 11168, zero is 5216\n",
      "layer: 33, number of nonzero weight is 23040, zero is 9728\n",
      "layer: 36, number of nonzero weight is 100017, zero is 47439\n",
      "layer: 39, number of nonzero weight is 45536, zero is 20000\n",
      "layer: 42, number of nonzero weight is 131072, zero is 0\n",
      "layer: 45, number of nonzero weight is 45625, zero is 19911\n",
      "layer: 48, number of nonzero weight is 103437, zero is 44019\n",
      "layer: 51, number of nonzero weight is 44167, zero is 21369\n",
      "layer: 54, number of nonzero weight is 45996, zero is 19540\n",
      "layer: 57, number of nonzero weight is 100890, zero is 46566\n",
      "layer: 60, number of nonzero weight is 44720, zero is 20816\n",
      "layer: 63, number of nonzero weight is 46040, zero is 19496\n",
      "layer: 66, number of nonzero weight is 102636, zero is 44820\n",
      "layer: 69, number of nonzero weight is 45028, zero is 20508\n",
      "layer: 72, number of nonzero weight is 92160, zero is 38912\n",
      "layer: 75, number of nonzero weight is 406728, zero is 183096\n",
      "layer: 78, number of nonzero weight is 183080, zero is 79064\n",
      "layer: 81, number of nonzero weight is 524288, zero is 0\n",
      "layer: 84, number of nonzero weight is 183711, zero is 78433\n",
      "layer: 87, number of nonzero weight is 413586, zero is 176238\n",
      "layer: 90, number of nonzero weight is 175157, zero is 86987\n",
      "layer: 93, number of nonzero weight is 183488, zero is 78656\n",
      "layer: 96, number of nonzero weight is 414243, zero is 175581\n",
      "layer: 99, number of nonzero weight is 176652, zero is 85492\n",
      "layer: 102, number of nonzero weight is 183984, zero is 78160\n",
      "layer: 105, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 108, number of nonzero weight is 172380, zero is 89764\n",
      "layer: 111, number of nonzero weight is 184070, zero is 78074\n",
      "layer: 114, number of nonzero weight is 414126, zero is 175698\n",
      "layer: 117, number of nonzero weight is 173052, zero is 89092\n",
      "layer: 120, number of nonzero weight is 184297, zero is 77847\n",
      "layer: 123, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 126, number of nonzero weight is 173672, zero is 88472\n",
      "layer: 129, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 132, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 135, number of nonzero weight is 175268, zero is 86876\n",
      "layer: 138, number of nonzero weight is 184299, zero is 77845\n",
      "layer: 141, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 144, number of nonzero weight is 178080, zero is 84064\n",
      "layer: 147, number of nonzero weight is 184302, zero is 77842\n",
      "layer: 150, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 153, number of nonzero weight is 177700, zero is 84444\n",
      "layer: 156, number of nonzero weight is 184193, zero is 77951\n",
      "layer: 159, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 162, number of nonzero weight is 180816, zero is 81328\n",
      "layer: 165, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 168, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 171, number of nonzero weight is 180436, zero is 81708\n",
      "layer: 174, number of nonzero weight is 184315, zero is 77829\n",
      "layer: 177, number of nonzero weight is 411390, zero is 178434\n",
      "layer: 180, number of nonzero weight is 179789, zero is 82355\n",
      "layer: 183, number of nonzero weight is 184318, zero is 77826\n",
      "layer: 186, number of nonzero weight is 413442, zero is 176382\n",
      "layer: 189, number of nonzero weight is 181776, zero is 80368\n",
      "layer: 192, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 195, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 198, number of nonzero weight is 182220, zero is 79924\n",
      "layer: 201, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 204, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 207, number of nonzero weight is 181196, zero is 80948\n",
      "layer: 210, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 213, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 216, number of nonzero weight is 178612, zero is 83532\n",
      "layer: 219, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 222, number of nonzero weight is 414072, zero is 175752\n",
      "layer: 225, number of nonzero weight is 179277, zero is 82867\n",
      "layer: 228, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 231, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 234, number of nonzero weight is 178764, zero is 83380\n",
      "layer: 237, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 240, number of nonzero weight is 414054, zero is 175770\n",
      "layer: 243, number of nonzero weight is 180552, zero is 81592\n",
      "layer: 246, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 249, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 252, number of nonzero weight is 182032, zero is 80112\n",
      "layer: 255, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 258, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 261, number of nonzero weight is 182032, zero is 80112\n",
      "layer: 264, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 267, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 270, number of nonzero weight is 181576, zero is 80568\n",
      "layer: 273, number of nonzero weight is 184320, zero is 77824\n",
      "layer: 276, number of nonzero weight is 414720, zero is 175104\n",
      "layer: 279, number of nonzero weight is 181880, zero is 80264\n",
      "layer: 282, number of nonzero weight is 367616, zero is 156672\n",
      "layer: 285, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 288, number of nonzero weight is 732831, zero is 315745\n",
      "layer: 291, number of nonzero weight is 2097152, zero is 0\n",
      "layer: 294, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 297, number of nonzero weight is 1654272, zero is 705024\n",
      "layer: 300, number of nonzero weight is 732984, zero is 315592\n",
      "layer: 303, number of nonzero weight is 735232, zero is 313344\n",
      "layer: 306, number of nonzero weight is 1652895, zero is 706401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 309, number of nonzero weight is 730864, zero is 317712\n",
      "Test: [0/196]\tTime 7.289 (7.289)\tLoss 0.7840 (0.7840)\tPrec@1 76.953 (76.953)\tPrec@5 98.047 (98.047)\n",
      " * Prec@1 55.210 Prec@5 80.408 Error@1 44.790\n",
      "\n",
      "\n",
      ">>>>> Accuracy_pruned:  55.21\n",
      " [resnet101] ::   6/ 10 ----- [[2020-10-04 04:00:43]] [Need: 14:19:48]\n",
      "Epoch: [6][0/5005]\tTime 30.880 (30.880)\tData 30.463 (30.463)\tLoss 2.0868 (2.0868)\tPrec@1 51.562 (51.562)\tPrec@5 76.953 (76.953)\n",
      "Epoch: [6][200/5005]\tTime 13.136 (2.728)\tData 12.768 (2.365)\tLoss 1.8541 (2.0472)\tPrec@1 55.078 (53.446)\tPrec@5 82.812 (77.284)\n",
      "Epoch: [6][400/5005]\tTime 9.765 (2.361)\tData 9.404 (1.997)\tLoss 2.1772 (2.0617)\tPrec@1 49.609 (53.201)\tPrec@5 72.656 (76.975)\n",
      "Epoch: [6][600/5005]\tTime 7.738 (2.179)\tData 7.252 (1.816)\tLoss 2.0082 (2.0658)\tPrec@1 52.344 (53.133)\tPrec@5 78.125 (76.900)\n",
      "Epoch: [6][800/5005]\tTime 15.347 (2.158)\tData 14.997 (1.796)\tLoss 2.1818 (2.0695)\tPrec@1 50.000 (53.008)\tPrec@5 72.266 (76.863)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/tf_tutorial/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][1000/5005]\tTime 15.207 (2.154)\tData 14.852 (1.792)\tLoss 2.3289 (2.0713)\tPrec@1 47.656 (53.016)\tPrec@5 71.875 (76.840)\n",
      "Epoch: [6][1200/5005]\tTime 19.171 (2.211)\tData 18.810 (1.849)\tLoss 2.0974 (2.0759)\tPrec@1 58.203 (52.948)\tPrec@5 75.781 (76.770)\n",
      "Epoch: [6][1400/5005]\tTime 25.076 (2.359)\tData 24.711 (1.997)\tLoss 2.0310 (2.0798)\tPrec@1 53.516 (52.912)\tPrec@5 80.078 (76.742)\n",
      "Epoch: [6][1600/5005]\tTime 22.078 (2.446)\tData 21.729 (2.084)\tLoss 2.2094 (2.0822)\tPrec@1 46.094 (52.855)\tPrec@5 74.609 (76.725)\n",
      "Epoch: [6][1800/5005]\tTime 19.571 (2.500)\tData 19.204 (2.138)\tLoss 2.0203 (2.0842)\tPrec@1 55.859 (52.828)\tPrec@5 76.562 (76.695)\n",
      "Epoch: [6][2000/5005]\tTime 22.323 (2.578)\tData 21.960 (2.217)\tLoss 1.9728 (2.0859)\tPrec@1 54.297 (52.797)\tPrec@5 75.781 (76.667)\n",
      "Epoch: [6][2200/5005]\tTime 14.437 (2.661)\tData 14.087 (2.299)\tLoss 1.8617 (2.0873)\tPrec@1 55.078 (52.777)\tPrec@5 78.516 (76.665)\n",
      "Epoch: [6][2400/5005]\tTime 22.946 (2.727)\tData 22.473 (2.365)\tLoss 2.2688 (2.0869)\tPrec@1 49.609 (52.768)\tPrec@5 71.094 (76.674)\n",
      "Epoch: [6][2600/5005]\tTime 19.312 (2.763)\tData 18.961 (2.401)\tLoss 1.9119 (2.0879)\tPrec@1 54.688 (52.738)\tPrec@5 79.688 (76.659)\n",
      "Epoch: [6][2800/5005]\tTime 21.993 (2.791)\tData 21.625 (2.430)\tLoss 2.0919 (2.0890)\tPrec@1 53.906 (52.710)\tPrec@5 79.297 (76.636)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "epoch_time = AverageMeter()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    need_hour, need_mins, need_secs = convert_secs2time(epoch_time.val * (args.epochs - epoch))\n",
    "    need_time = '[Need: {:02d}:{:02d}:{:02d}]'.format(need_hour, need_mins, need_secs)\n",
    "    print_log(\n",
    "        ' [{:s}] :: {:3d}/{:3d} ----- [{:s}] {:s}'.format(\n",
    "            args.arch, epoch, args.epochs, time_string(), need_time),\n",
    "        log)\n",
    "\n",
    "    \n",
    "    # 1. train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch, log)\n",
    "    \n",
    "\n",
    "    # 2. evaluate on validation set\n",
    "    val_acc_1 = validate(val_loader, model, criterion, log)\n",
    "    print('\\n\\n>>>>> Accuracy_model: ', val_acc_1)\n",
    "    \n",
    "    # 3. prune trained model - filter again after 1 training epoch\n",
    "    if (epoch % args.epoch_prune == 0 or epoch == args.epochs - 1):\n",
    "        #        if (random.randint(1,args.epoch_prune)==1 or epoch == args.epochs-1):\n",
    "        m.model = model\n",
    "        m.if_zero()\n",
    "        m.init_mask(args.rate)\n",
    "        m.do_mask()\n",
    "        m.if_zero()\n",
    "        model = m.model\n",
    "        if args.use_cuda:\n",
    "            model = model.cuda()\n",
    "\n",
    "    # 4. validate pruned model\n",
    "    val_acc_2 = validate(val_loader, model, criterion, log)\n",
    "    print('\\n\\n>>>>> Accuracy_pruned: ', val_acc_2)\n",
    "    \n",
    "    \n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = val_acc_2 > best_prec1\n",
    "    best_prec1 = max(val_acc_2, best_prec1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, filename, bestname)\n",
    "    # measure elapsed time\n",
    "    epoch_time.update(time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.evaluate:\n",
    "    validate(val_loader, model, criterion, log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_tutorial",
   "language": "python",
   "name": "tf_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
