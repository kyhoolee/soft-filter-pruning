{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/vision/blob/master/torchvision/models/__init__.py\n",
    "import argparse\n",
    "import os,sys\n",
    "import shutil\n",
    "import pdb, time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models\n",
    "from utils import convert_secs2time, time_string, time_file_str\n",
    "# from models import print_log\n",
    "import models\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python ./utils/get_small_model.py \n",
    "# /home/hongky/datasets/imagenet \n",
    "# -a resnet101  --workers 12 \n",
    "# --resume  ./0810_resnet101/resnet101-rate-0.7/best.resnet101.2020-10-08-2702.pth.tar \n",
    "# --save_dir ./0810_resnet101/resnet101-rate-0.7/infer_small_model/ \n",
    "# --batch-size 64 \n",
    "# --rate 0.7 --get_small\n",
    "\n",
    "from dotmap import DotMap\n",
    "\n",
    "args = DotMap()\n",
    "args.data = '/home/hongky/datasets/imagenet'\n",
    "args.save_dir = './0810_resnet101/resnet101-rate-0.7/infer_small_model/'\n",
    "args.arch = 'resnet101'\n",
    "args.workers = 12\n",
    "args.batch_size = 64\n",
    "args.lr = 0.1\n",
    "args.print_freq = 200\n",
    "args.resume = './0810_resnet101/resnet101-rate-0.7/best.resnet101.2020-10-08-2702.pth.tar'\n",
    "args.rate = 0.7\n",
    "args.layer_begin = 3\n",
    "args.layer_end = 3\n",
    "args.layer_inter = 1\n",
    "args.epoch_prune = 1\n",
    "args.skip_downsample = 1\n",
    "args.get_small = True \n",
    "args.use_cuda = True\n",
    "\n",
    "args.prefix = time_file_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, log, is_cuda=False):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        # target = target.cuda(async=True)\n",
    "        if is_cuda:\n",
    "            input = input.cuda()\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print_log('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                top1=top1, top5=top5), log)\n",
    "\n",
    "    print_log(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Error@1 {error1:.3f}'.format(top1=top1, top5=top5,\n",
    "                                                                                           error1=100 - top1.avg), log)\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename, bestname):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, bestname)\n",
    "\n",
    "\n",
    "def print_log(print_string, log):\n",
    "    print(\"{}\".format(print_string))\n",
    "    log.write('{}\\n'.format(print_string))\n",
    "    log.flush()\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def remove_module_dict(state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:]  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet101'\n",
      "=> Model : ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "=> parameter : DotMap(data='/home/hongky/datasets/imagenet', save_dir='./0810_resnet101/resnet101-rate-0.7/infer_small_model/', arch='resnet101', workers=12, batch_size=64, lr=0.1, print_freq=200, resume='./0810_resnet101/resnet101-rate-0.7/best.resnet101.2020-10-08-2702.pth.tar', rate=0.7, layer_begin=3, layer_end=3, layer_inter=1, epoch_prune=1, skip_downsample=1, get_small=True, use_cuda=True, prefix='2020-10-15-8538')\n",
      "Compress Rate: 0.7\n",
      "Layer Begin: 3\n",
      "Layer End: 3\n",
      "Layer Inter: 1\n",
      "Epoch prune: 1\n",
      "Skip downsample : 1\n",
      "=> loading checkpoint './0810_resnet101/resnet101-rate-0.7/best.resnet101.2020-10-08-2702.pth.tar'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint './0810_resnet101/resnet101-rate-0.7/best.resnet101.2020-10-08-2702.pth.tar' (epoch 94)\n"
     ]
    }
   ],
   "source": [
    "best_prec1 = 0\n",
    "\n",
    "if not os.path.isdir(args.save_dir):\n",
    "    os.makedirs(args.save_dir)\n",
    "log = open(os.path.join(args.save_dir, 'gpu-time.{}.{}.log'.format(args.arch, args.prefix)), 'w')\n",
    "\n",
    "# create model\n",
    "print_log(\"=> creating model '{}'\".format(args.arch), log)\n",
    "model = models.__dict__[args.arch](pretrained=False)\n",
    "print_log(\"=> Model : {}\".format(model), log)\n",
    "print_log(\"=> parameter : {}\".format(args), log)\n",
    "print_log(\"Compress Rate: {}\".format(args.rate), log)\n",
    "print_log(\"Layer Begin: {}\".format(args.layer_begin), log)\n",
    "print_log(\"Layer End: {}\".format(args.layer_end), log)\n",
    "print_log(\"Layer Inter: {}\".format(args.layer_inter), log)\n",
    "print_log(\"Epoch prune: {}\".format(args.epoch_prune), log)\n",
    "print_log(\"Skip downsample : {}\".format(args.skip_downsample), log)\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print_log(\"=> loading checkpoint '{}'\".format(args.resume), log)\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        state_dict = remove_module_dict(state_dict)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print_log(\"=> loaded checkpoint '{}' (epoch {})\".format(args.resume, checkpoint['epoch']), log)\n",
    "    else:\n",
    "        print_log(\"=> no checkpoint found at '{}'\".format(args.resume), log)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Data loading code\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        # transforms.Scale(256),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_channel(tensor):\n",
    "    #print('DEBUG: tensor-size')\n",
    "    #print(tensor.size())\n",
    "    #print(len(tensor.size()))\n",
    "#     if len(tensor.size()) == 0:\n",
    "#         return 0, 0\n",
    "    size_0 = tensor.size()[0]\n",
    "    size_1 = tensor.size()[1] * tensor.size()[2] * tensor.size()[3]\n",
    "    tensor_resize = tensor.view(size_0, -1)\n",
    "    # indicator: if the channel contain all zeros\n",
    "    channel_if_zero = np.zeros(size_0)\n",
    "    for x in range(0, size_0, 1):\n",
    "        channel_if_zero[x] = np.count_nonzero(tensor_resize[x].cpu().numpy()) != 0\n",
    "    # indices = (torch.LongTensor(channel_if_zero) != 0 ).nonzero().view(-1)\n",
    "\n",
    "    indices_nonzero = torch.LongTensor((channel_if_zero != 0).nonzero()[0])\n",
    "    # indices_nonzero = torch.LongTensor((channel_if_zero != 0).nonzero()[0])\n",
    "\n",
    "    zeros = (channel_if_zero == 0).nonzero()[0]\n",
    "    indices_zero = torch.LongTensor(zeros) if zeros != [] else []\n",
    "\n",
    "    return indices_zero, indices_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of state dict is 626\n",
      "\n",
      "\n",
      "\n",
      "conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([64, 3, 7, 7])\n",
      "indices_zero 19 ++ indices_nonzero 45\n",
      "bn1.weight <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "bn1.bias <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.0.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([64, 64, 1, 1])\n",
      "indices_zero 19 ++ indices_nonzero 45\n",
      "layer1.0.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.0.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([64, 64, 3, 3])\n",
      "indices_zero 19 ++ indices_nonzero 45\n",
      "layer1.0.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.0.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.0.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 64, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer1.0.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.0.downsample.0.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 64, 1, 1])\n",
      "indices_zero 0 ++ indices_nonzero 256\n",
      "layer1.0.downsample.1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.downsample.1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.downsample.1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.downsample.1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.0.downsample.1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.1.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([64, 256, 1, 1])\n",
      "indices_zero 19 ++ indices_nonzero 45\n",
      "layer1.1.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.1.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([64, 64, 3, 3])\n",
      "indices_zero 19 ++ indices_nonzero 45\n",
      "layer1.1.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.1.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.1.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 64, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer1.1.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.1.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.1.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.1.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.1.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.2.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([64, 256, 1, 1])\n",
      "indices_zero 19 ++ indices_nonzero 45\n",
      "layer1.2.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.2.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([64, 64, 3, 3])\n",
      "indices_zero 19 ++ indices_nonzero 45\n",
      "layer1.2.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([64])\n",
      "layer1.2.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer1.2.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 64, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer1.2.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.2.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.2.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.2.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer1.2.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.0.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 256, 1, 1])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.0.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.0.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 128, 3, 3])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.0.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.0.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.0.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 128, 1, 1])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer2.0.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.0.downsample.0.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 256, 1, 1])\n",
      "indices_zero 0 ++ indices_nonzero 512\n",
      "layer2.0.downsample.1.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.downsample.1.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.downsample.1.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.downsample.1.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.0.downsample.1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.1.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 512, 1, 1])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.1.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.1.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 128, 3, 3])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.1.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.1.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.1.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 128, 1, 1])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer2.1.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.1.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.1.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.1.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.1.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.2.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 512, 1, 1])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.2.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.2.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 128, 3, 3])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.2.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.2.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.2.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 128, 1, 1])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer2.2.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.2.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.2.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.2.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.2.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.3.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 512, 1, 1])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.3.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.3.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([128, 128, 3, 3])\n",
      "indices_zero 38 ++ indices_nonzero 90\n",
      "layer2.3.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([128])\n",
      "layer2.3.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer2.3.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 128, 1, 1])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer2.3.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.3.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.3.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.3.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer2.3.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.0.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 512, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.0.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.0.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.0.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.0.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.0.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.0.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.0.downsample.0.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 512, 1, 1])\n",
      "indices_zero 0 ++ indices_nonzero 1024\n",
      "layer3.0.downsample.1.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.downsample.1.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.downsample.1.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.downsample.1.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.0.downsample.1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.1.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.1.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.1.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.1.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.1.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.1.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.1.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.1.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.1.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.1.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.1.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.2.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.2.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.2.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.2.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.2.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.2.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.2.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.2.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.2.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.2.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.2.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.3.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.3.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.3.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.3.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.3.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.3.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.3.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.3.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.3.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.3.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.3.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.4.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.4.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.4.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.4.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.4.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.4.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.4.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.4.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.4.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.4.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.4.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.5.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.5.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.5.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.5.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.5.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.5.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.5.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.5.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.5.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.5.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.5.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.6.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.6.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.6.conv2.weight <class 'torch.Tensor'>\n",
      "++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.6.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.6.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.6.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.6.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.6.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.6.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.6.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.6.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.7.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.7.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.7.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.7.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.7.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.7.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.7.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.7.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.7.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.7.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.7.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.8.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.8.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.8.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.8.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.8.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.8.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.8.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.8.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.8.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.8.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.8.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.9.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.9.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.9.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.9.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.9.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.9.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.9.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.9.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.9.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.9.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.9.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.10.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.10.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.10.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.10.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.10.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.10.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.10.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.10.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.10.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.10.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.10.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.11.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.11.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.11.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.11.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.11.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.11.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.11.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.11.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.11.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.11.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.11.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.12.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.12.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.12.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.12.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.12.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.12.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.12.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.12.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.12.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.12.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.12.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.13.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.13.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.13.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.13.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.13.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.13.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.13.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.13.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.13.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.13.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.13.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.14.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.14.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.14.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.14.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.14.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.14.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.14.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.14.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.14.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.14.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.14.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.15.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.15.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.15.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.15.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.15.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.15.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.15.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.15.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.15.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.15.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.15.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.16.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.16.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.16.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.16.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.16.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.16.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.16.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.16.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.16.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.16.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.16.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.17.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.17.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.17.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.17.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.17.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.17.conv3.weight <class 'torch.Tensor'>\n",
      "++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.17.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.17.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.17.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.17.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.17.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.18.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.18.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.18.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.18.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.18.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.18.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.18.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.18.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.18.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.18.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.18.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.19.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.19.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.19.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.19.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.19.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.19.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.19.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.19.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.19.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.19.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.19.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.20.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.20.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.20.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.20.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.20.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.20.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.20.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.20.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.20.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.20.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.20.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.21.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.21.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.21.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.21.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.21.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.21.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.21.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.21.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.21.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.21.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.21.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.22.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 1024, 1, 1])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.22.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.22.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([256, 256, 3, 3])\n",
      "indices_zero 76 ++ indices_nonzero 180\n",
      "layer3.22.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([256])\n",
      "layer3.22.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer3.22.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([1024, 256, 1, 1])\n",
      "indices_zero 307 ++ indices_nonzero 717\n",
      "layer3.22.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.22.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.22.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.22.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([1024])\n",
      "layer3.22.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.0.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 1024, 1, 1])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer4.0.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.0.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 512, 3, 3])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer4.0.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.0.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.0.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([2048, 512, 1, 1])\n",
      "indices_zero 614 ++ indices_nonzero 1434\n",
      "layer4.0.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.0.downsample.0.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([2048, 1024, 1, 1])\n",
      "indices_zero 0 ++ indices_nonzero 2048\n",
      "layer4.0.downsample.1.weight <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.downsample.1.bias <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.downsample.1.running_mean <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.downsample.1.running_var <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.0.downsample.1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.1.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 2048, 1, 1])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer4.1.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.1.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 512, 3, 3])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer4.1.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.1.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.1.conv3.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([2048, 512, 1, 1])\n",
      "indices_zero 614 ++ indices_nonzero 1434\n",
      "layer4.1.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.1.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.1.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.1.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.1.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.2.conv1.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 2048, 1, 1])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer4.2.bn1.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn1.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn1.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn1.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn1.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.2.conv2.weight <class 'torch.Tensor'>\n",
      "++\n",
      "shape:  torch.Size([512, 512, 3, 3])\n",
      "indices_zero 153 ++ indices_nonzero 359\n",
      "layer4.2.bn2.weight <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn2.bias <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn2.running_mean <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn2.running_var <class 'torch.Tensor'>  ::  torch.Size([512])\n",
      "layer4.2.bn2.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "\n",
      "\n",
      "\n",
      "layer4.2.conv3.weight <class 'torch.Tensor'>\n",
      "++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([2048, 512, 1, 1])\n",
      "indices_zero 614 ++ indices_nonzero 1434\n",
      "layer4.2.bn3.weight <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.2.bn3.bias <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.2.bn3.running_mean <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.2.bn3.running_var <class 'torch.Tensor'>  ::  torch.Size([2048])\n",
      "layer4.2.bn3.num_batches_tracked <class 'torch.Tensor'>  ::  torch.Size([])\n",
      "fc.weight <class 'torch.Tensor'>  ::  torch.Size([1000, 2048])\n",
      "fc.bias <class 'torch.Tensor'>  ::  torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "big_model = model\n",
    "\n",
    "item = list(big_model.state_dict().items())\n",
    "\n",
    "print(\"length of state dict is\", len(item))\n",
    "\n",
    "\n",
    "#print('big_model: ', big_model)\n",
    "#print('big_model.state_dict():', big_model.state_dict())\n",
    "\n",
    "# indices_list = []\n",
    "kept_index_per_layer = {}\n",
    "kept_filter_per_layer = {}\n",
    "pruned_index_per_layer = {}\n",
    "\n",
    "#print('item[0]: ', item[0])\n",
    "#     param_names = [(it[0], it[1].size()) for it in item]\n",
    "#     for v in param_names:\n",
    "#         print(v)\n",
    "\n",
    "#     print('\\n\\n')\n",
    "\n",
    "for x in range(0, len(item), 1):\n",
    "    # print(item[x][0])\n",
    "    if(len(item[x][1].size()) == 4):\n",
    "        print('\\n\\n')\n",
    "        print(item[x][0], type(item[x][1]))\n",
    "        print('++')\n",
    "        indices_zero, indices_nonzero = check_channel(item[x][1])\n",
    "        print('shape: ', item[x][1].size())\n",
    "        print('indices_zero {} ++ indices_nonzero {}'.format(len(indices_zero), len(indices_nonzero)))\n",
    "        # indices_list.append(indices_nonzero)\n",
    "        pruned_index_per_layer[item[x][0]] = indices_zero\n",
    "        kept_index_per_layer[item[x][0]] = indices_nonzero\n",
    "        kept_filter_per_layer[item[x][0]] = indices_nonzero.shape[0]\n",
    "        \n",
    "    else:\n",
    "        print(item[x][0], type(item[x][1]), ' :: ', item[x][1].size())\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_conv_bn(conv1, bn1, inplanes, inplanes_indices=None, kernel_size=1, stride=1, padding=0, bias=False):\n",
    "    indices_zero, indices_nonzero = check_channel(conv1.weight.detach())\n",
    "    print(len(indices_zero), len(indices_nonzero))\n",
    "    n_outplanes = len(indices_nonzero)\n",
    "\n",
    "    n_conv1 = nn.Conv2d(inplanes, n_outplanes, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                   bias=bias)\n",
    "\n",
    "#     print('-------------\\n conv1')\n",
    "    state_dict = {}\n",
    "    for k in conv1.state_dict().keys():\n",
    "\n",
    "        vals = conv1.state_dict()[k]\n",
    "#         print('param: ', k, type(vals), vals.size())\n",
    "        state_dict[k] = torch.index_select(vals, 0, indices_nonzero)\n",
    "        if inplanes_indices != None:\n",
    "            state_dict[k] = torch.index_select(state_dict[k], 1, inplanes_indices)\n",
    "    n_conv1.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "#     print('-------------\\n bn1')\n",
    "    state_dict = {}\n",
    "    \n",
    "    n_bn1 = nn.BatchNorm2d(len(indices_nonzero))\n",
    "    for k in bn1.state_dict().keys():\n",
    "        vals = bn1.state_dict()[k]\n",
    "#         print('param: ', k, type(vals), vals.size())\n",
    "        if(len(vals.size()) > 0):\n",
    "            state_dict[k] = torch.index_select(vals, 0, indices_nonzero)\n",
    "        else:\n",
    "            state_dict[k] = vals\n",
    "\n",
    "    n_bn1.load_state_dict(state_dict)\n",
    "    \n",
    "    return n_conv1, n_bn1, n_outplanes, indices_nonzero\n",
    "\n",
    "\n",
    "def prune_inplane_conv_bn(conv1, bn1, inplanes, inplanes_indices=None, kernel_size=1, stride=1, padding=0, bias=False):\n",
    "    n_outplanes = conv1.weight.size()[0]\n",
    "\n",
    "    n_conv1 = nn.Conv2d(inplanes, n_outplanes, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                   bias=bias)\n",
    "\n",
    "#     print('-------------\\n conv1')\n",
    "    state_dict = {}\n",
    "    for k in conv1.state_dict().keys():\n",
    "\n",
    "        vals = conv1.state_dict()[k]\n",
    "        if inplanes_indices != None:\n",
    "            state_dict[k] = torch.index_select(vals, 1, inplanes_indices)\n",
    "        else:\n",
    "            state_dict[k] = vals\n",
    "    n_conv1.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "    n_bn1 = bn1\n",
    "    \n",
    "    indices_nonzero = None\n",
    "    \n",
    "    return n_conv1, n_bn1, n_outplanes, indices_nonzero\n",
    "\n",
    "\n",
    "\n",
    "class PrunedBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, origin_block, inplanes, inplanes_indices, stride=1, downsample=None):\n",
    "        super(PrunedBottleneck, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv1, bn1, next_inplanes, next_inplanes_indices = prune_conv_bn(origin_block.conv1, origin_block.bn1, \n",
    "                                   inplanes, inplanes_indices, \n",
    "                                   kernel_size=1, bias=False)\n",
    "        self.conv1 = conv1\n",
    "        self.bn1 = bn1\n",
    "        \n",
    "        \n",
    "        conv2, bn2, next_inplanes, next_inplanes_indices = prune_conv_bn(origin_block.conv2, origin_block.bn2,\n",
    "                               next_inplanes, next_inplanes_indices,  \n",
    "                               kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.conv2 = conv2\n",
    "        self.bn2 = bn2\n",
    "        \n",
    "        \n",
    "        conv3, bn3, next_inplanes, next_inplanes_indices = prune_inplane_conv_bn(origin_block.conv3, origin_block.bn3,\n",
    "                               next_inplanes, next_inplanes_indices,  \n",
    "                               kernel_size=1, bias=False)\n",
    "        self.conv3 = conv3\n",
    "        self.bn3 = bn3\n",
    "        \n",
    "        \n",
    "        self.next_inplanes = next_inplanes\n",
    "        self.next_inplanes_indices = next_inplanes_indices\n",
    "        \n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "#         print('block-0:', x.size())\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "#         print('block-1:', out.size())\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "#         print('block-2:', out.size())\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "#         print('block-3:', out.size())\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "#             print('residual:', residual.size())\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CloneBottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, origin_block, inplanes, inplanes_indices, stride=1, downsample=None):\n",
    "        super(CloneBottleneck, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv1, bn1, next_inplanes, next_inplanes_indices = prune_inplane_conv_bn(origin_block.conv1, origin_block.bn1, \n",
    "                                   inplanes, inplanes_indices, \n",
    "                                   kernel_size=1, bias=False)\n",
    "        self.conv1 = conv1\n",
    "        self.bn1 = bn1\n",
    "        \n",
    "        \n",
    "        conv2, bn2, next_inplanes, next_inplanes_indices = prune_inplane_conv_bn(origin_block.conv2, origin_block.bn2,\n",
    "                               next_inplanes, next_inplanes_indices,  \n",
    "                               kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.conv2 = conv2\n",
    "        self.bn2 = bn2\n",
    "        \n",
    "        \n",
    "        conv3, bn3, next_inplanes, next_inplanes_indices = prune_inplane_conv_bn(origin_block.conv3, origin_block.bn3,\n",
    "                               next_inplanes, next_inplanes_indices,  \n",
    "                               kernel_size=1, bias=False)\n",
    "        self.conv3 = conv3\n",
    "        self.bn3 = bn3\n",
    "        \n",
    "        \n",
    "        self.next_inplanes = next_inplanes\n",
    "        self.next_inplanes_indices = next_inplanes_indices\n",
    "        \n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        #print('block-0:', x.size())\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        #print('block-1:', out.size())\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        #print('block-2:', out.size())\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        #print('block-3:', out.size())\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            #print('residual:', residual.size())\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_downsample(origin_downsample, conv3, inplanes, inplanes_indices, stride):\n",
    "    indices_zero, indices_nonzero = check_channel(conv3.weight.detach())\n",
    "    print(len(indices_zero), len(indices_nonzero))\n",
    "    n_outplanes = len(indices_nonzero)\n",
    "    \n",
    "    \n",
    "    conv1 = origin_downsample[0]\n",
    "    bn1 = origin_downsample[1]\n",
    "    \n",
    "    n_conv1 = nn.Conv2d(inplanes, n_outplanes,\n",
    "                        kernel_size=1, stride=stride, bias=False)\n",
    "                \n",
    "            \n",
    "    #     print('-------------\\n conv1')\n",
    "    state_dict = {}\n",
    "    for k in conv1.state_dict().keys():\n",
    "\n",
    "        vals = conv1.state_dict()[k]\n",
    "#         print('param: ', k, type(vals), vals.size())\n",
    "        state_dict[k] = torch.index_select(vals, 0, indices_nonzero)\n",
    "        if inplanes_indices != None:\n",
    "            state_dict[k] = torch.index_select(state_dict[k], 1, inplanes_indices)\n",
    "    n_conv1.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "#     print('-------------\\n bn1')\n",
    "    state_dict = {}\n",
    "    \n",
    "    n_bn1 = nn.BatchNorm2d(n_outplanes)\n",
    "    for k in bn1.state_dict().keys():\n",
    "        vals = bn1.state_dict()[k]\n",
    "#         print('param: ', k, type(vals), vals.size())\n",
    "        if(len(vals.size()) > 0):\n",
    "            state_dict[k] = torch.index_select(vals, 0, indices_nonzero)\n",
    "        else:\n",
    "            state_dict[k] = vals\n",
    "\n",
    "    n_bn1.load_state_dict(state_dict)\n",
    "    \n",
    "    n_downsample = nn.Sequential(n_conv1, n_bn1)\n",
    "    return n_downsample\n",
    "\n",
    "\n",
    "def make_normal_downsample(origin_downsample, inplanes, inplanes_indices, stride):\n",
    "    conv1 = origin_downsample[0]\n",
    "    bn1 = origin_downsample[1]\n",
    "    \n",
    "    n_outplanes = conv1.weight.size()[0]\n",
    "    \n",
    "    n_conv1 = nn.Conv2d(inplanes, n_outplanes,\n",
    "                        kernel_size=1, stride=stride, bias=False)\n",
    "                \n",
    "    state_dict = {}\n",
    "    for k in conv1.state_dict().keys():\n",
    "        vals = conv1.state_dict()[k]\n",
    "        if inplanes_indices != None:\n",
    "            state_dict[k] = torch.index_select(vals, 1, inplanes_indices)\n",
    "        else:\n",
    "            state_dict[k] = vals\n",
    "    n_conv1.load_state_dict(state_dict)\n",
    "\n",
    "    n_bn1 = bn1\n",
    "    \n",
    "    n_downsample = nn.Sequential(n_conv1, n_bn1)\n",
    "    return n_downsample\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PruneResNet101(nn.Module):\n",
    "\n",
    "    def __init__(self, origin_model, layers=[3,4,23,3], num_classes=1000):\n",
    "        super(PruneResNet101, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv1, bn1, next_inplanes, next_inplanes_indices = prune_conv_bn(origin_model.conv1, origin_model.bn1, \n",
    "                                   inplanes=3, inplanes_indices=None, \n",
    "                                   kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        self.conv1 = conv1\n",
    "        self.bn1 = bn1\n",
    "\n",
    "#         self.conv1 = origin_model.conv1\n",
    "#         self.bn1 = origin_model.bn1\n",
    "#         next_inplanes = 64\n",
    "#         next_inplanes_indices = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.layer1, next_inplanes, next_inplanes_indices = self._make_layer(\n",
    "                                    origin_model.layer1,\n",
    "                                    next_inplanes, next_inplanes_indices, \n",
    "                                    layers[0])\n",
    "        print('origin_layer1::')\n",
    "        print(origin_model.layer1)\n",
    "        print('======')\n",
    "        print('layer1::')\n",
    "        print(self.layer1)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.layer2, next_inplanes, next_inplanes_indices = self._make_layer(\n",
    "                                    origin_model.layer2,\n",
    "                                    next_inplanes, next_inplanes_indices,  \n",
    "                                    layers[1], stride=2)\n",
    "        print('origin_layer2::')\n",
    "        print(origin_model.layer2)\n",
    "        print('======')\n",
    "        print('layer2::')\n",
    "        print(self.layer2)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.layer3, next_inplanes, next_inplanes_indices = self._make_layer(\n",
    "                                    origin_model.layer3,\n",
    "                                    next_inplanes, next_inplanes_indices,  \n",
    "                                    layers[2], stride=2)\n",
    "        print('origin_layer3::')\n",
    "        print(origin_model.layer3)\n",
    "        print('======')\n",
    "        print('layer3::')\n",
    "        print(self.layer3)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.layer4, next_inplanes, next_inplanes_indices = self._make_layer(\n",
    "                                    origin_model.layer4,\n",
    "                                    next_inplanes, next_inplanes_indices,  \n",
    "                                    layers[3], stride=2)\n",
    "        print('origin_layer4::')\n",
    "        print(origin_model.layer4)\n",
    "        print('======')\n",
    "        print('layer4::')\n",
    "        print(self.layer4)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        \n",
    "        \n",
    "        fc = nn.Linear(next_inplanes, num_classes)\n",
    "        o_fc = origin_model.fc\n",
    "        state_dict = {}\n",
    "        for k in o_fc.state_dict().keys():\n",
    "            vals = o_fc.state_dict()[k]\n",
    "            if(len(vals.size()) > 1):\n",
    "                state_dict[k] = torch.index_select(vals, 1, next_inplanes_indices)\n",
    "            else:\n",
    "                state_dict[k] = vals\n",
    "                \n",
    "        fc.load_state_dict(state_dict)\n",
    "        \n",
    "        \n",
    "        self.fc = fc\n",
    "\n",
    "        \n",
    "\n",
    "    def _make_layer(self, origin_layer, inplanes, inplanes_indices, blocks, stride=1):\n",
    "        print('blocks: ', blocks)\n",
    "        layers = []\n",
    "        \n",
    "        block0 = origin_layer[0]\n",
    "        downsample = make_downsample(block0.downsample, block0.conv3, inplanes, inplanes_indices, stride)\n",
    "        \n",
    "        \n",
    "        # origin_block, inplanes, inplanes_indices, stride=1, downsample=None\n",
    "        new_block0 = PrunedBottleneck(block0, inplanes, inplanes_indices, stride, downsample)\n",
    "        inplanes = new_block0.next_inplanes\n",
    "        inplanes_indices = new_block0.next_inplanes_indices\n",
    "        \n",
    "        layers.append(new_block0)\n",
    "        \n",
    "        \n",
    "        for i in range(1, blocks):\n",
    "            blocki = origin_layer[i]\n",
    "            new_blocki = PrunedBottleneck(blocki, inplanes, inplanes_indices, downsample=None)\n",
    "            inplanes = new_blocki.next_inplanes\n",
    "            inplanes_indices = new_blocki.next_inplanes_indices\n",
    "            layers.append(new_blocki)\n",
    "\n",
    "        return nn.Sequential(*layers), inplanes, inplanes_indices\n",
    "    \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        \n",
    "#         print('0: ',x.size())\n",
    "\n",
    "        x = self.layer1(x)\n",
    "#         print('1: ',x.size())\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "#         print('2: ',x.size())\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "#         print('3: ',x.size())\n",
    "        \n",
    "        x = self.layer4(x)\n",
    "#         print('4: ',x.size())\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CloneResNet101(nn.Module):\n",
    "\n",
    "    def __init__(self, origin_model, layers=[3,4,23,3], num_classes=1000):\n",
    "        super(CloneResNet101, self).__init__()\n",
    "        \n",
    "        \n",
    "#         conv1, bn1, next_inplanes, next_inplanes_indices = prune_conv_bn(origin_model.conv1, origin_model.bn1, \n",
    "#                                    inplanes=3, inplanes_indices=None, \n",
    "#                                    kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "#         self.conv1 = conv1\n",
    "#         self.bn1 = bn1\n",
    "\n",
    "        self.conv1 = origin_model.conv1\n",
    "        self.bn1 = origin_model.bn1\n",
    "        next_inplanes = 64\n",
    "        next_inplanes_indices = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.layer1, next_inplanes, next_inplanes_indices = self._make_normal_layer(\n",
    "                                    origin_model.layer1,\n",
    "                                    next_inplanes, next_inplanes_indices, \n",
    "                                    layers[0])\n",
    "#         print('origin_layer1::')\n",
    "#         print(origin_model.layer1)\n",
    "        print('======')\n",
    "        print('layer1::')\n",
    "        print(self.layer1)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.layer2, next_inplanes, next_inplanes_indices = self._make_normal_layer(\n",
    "                                    origin_model.layer2,\n",
    "                                    next_inplanes, next_inplanes_indices,  \n",
    "                                    layers[1], stride=2)\n",
    "#         print('origin_layer2::')\n",
    "#         print(origin_model.layer2)\n",
    "        print('======')\n",
    "        print('layer2::')\n",
    "        print(self.layer2)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.layer3, next_inplanes, next_inplanes_indices = self._make_mix_layer(\n",
    "                                    origin_model.layer3,\n",
    "                                    next_inplanes, next_inplanes_indices,  \n",
    "                                    layers[2], stride=2)\n",
    "#         print('origin_layer3::')\n",
    "#         print(origin_model.layer3)\n",
    "        print('======')\n",
    "        print('layer3::')\n",
    "        print(self.layer3)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.layer4, next_inplanes, next_inplanes_indices = self._make_normal_layer(\n",
    "                                    origin_model.layer4,\n",
    "                                    next_inplanes, next_inplanes_indices,  \n",
    "                                    layers[3], stride=2)\n",
    "        print('origin_layer4::')\n",
    "        print(origin_model.layer4)\n",
    "        print('======')\n",
    "        print('layer4::')\n",
    "        print(self.layer4)\n",
    "        print('---\\n\\n')\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        \n",
    "        \n",
    "#         fc = nn.Linear(next_inplanes, num_classes)\n",
    "#         o_fc = origin_model.fc\n",
    "#         state_dict = {}\n",
    "#         for k in o_fc.state_dict().keys():\n",
    "#             vals = o_fc.state_dict()[k]\n",
    "#             if(len(vals.size()) > 1):\n",
    "#                 state_dict[k] = torch.index_select(vals, 1, next_inplanes_indices)\n",
    "#             else:\n",
    "#                 state_dict[k] = vals\n",
    "                \n",
    "#         fc.load_state_dict(state_dict)\n",
    "        \n",
    "        \n",
    "        self.fc = origin_model.fc\n",
    "\n",
    "        \n",
    "\n",
    "    def _make_layer(self, origin_layer, inplanes, inplanes_indices, blocks, stride=1):\n",
    "        print('blocks: ', blocks)\n",
    "        layers = []\n",
    "        \n",
    "        block0 = origin_layer[0]\n",
    "        downsample = make_downsample(block0.downsample, block0.conv3, inplanes, inplanes_indices, stride)\n",
    "        \n",
    "        \n",
    "        # origin_block, inplanes, inplanes_indices, stride=1, downsample=None\n",
    "        new_block0 = PrunedBottleneck(block0, inplanes, inplanes_indices, stride, downsample)\n",
    "        inplanes = new_block0.next_inplanes\n",
    "        inplanes_indices = new_block0.next_inplanes_indices\n",
    "        \n",
    "        layers.append(new_block0)\n",
    "        \n",
    "        \n",
    "        for i in range(1, blocks):\n",
    "            blocki = origin_layer[i]\n",
    "            new_blocki = PrunedBottleneck(blocki, inplanes, inplanes_indices, downsample=None)\n",
    "            inplanes = new_blocki.next_inplanes\n",
    "            inplanes_indices = new_blocki.next_inplanes_indices\n",
    "            layers.append(new_blocki)\n",
    "\n",
    "        return nn.Sequential(*layers), inplanes, inplanes_indices\n",
    "    \n",
    "    \n",
    "    def _make_normal_layer(self, origin_layer, inplanes, inplanes_indices, blocks, stride=1):\n",
    "        print('blocks: ', blocks)\n",
    "        layers = []\n",
    "        \n",
    "        block0 = origin_layer[0]\n",
    "        downsample = make_normal_downsample(block0.downsample, inplanes, inplanes_indices, stride)\n",
    "        \n",
    "        \n",
    "        # origin_block, inplanes, inplanes_indices, stride=1, downsample=None\n",
    "        new_block0 = CloneBottleneck(block0, inplanes, inplanes_indices, stride, downsample)\n",
    "        inplanes = new_block0.next_inplanes\n",
    "        inplanes_indices = new_block0.next_inplanes_indices\n",
    "        \n",
    "        layers.append(new_block0)\n",
    "        \n",
    "        \n",
    "        for i in range(1, blocks):\n",
    "            blocki = origin_layer[i]\n",
    "            new_blocki = CloneBottleneck(blocki, inplanes, inplanes_indices, downsample=None)\n",
    "            inplanes = new_blocki.next_inplanes\n",
    "            inplanes_indices = new_blocki.next_inplanes_indices\n",
    "            layers.append(new_blocki)\n",
    "\n",
    "        return nn.Sequential(*layers), inplanes, inplanes_indices\n",
    "    \n",
    "    \n",
    "    def _make_mix_layer(self, origin_layer, inplanes, inplanes_indices, blocks, stride=1):\n",
    "        print('blocks: ', blocks)\n",
    "        layers = []\n",
    "        \n",
    "        block0 = origin_layer[0]\n",
    "        downsample = make_normal_downsample(block0.downsample, inplanes, inplanes_indices, stride)\n",
    "        \n",
    "        \n",
    "        # origin_block, inplanes, inplanes_indices, stride=1, downsample=None\n",
    "        new_block0 = PrunedBottleneck(block0, inplanes, inplanes_indices, stride, downsample)\n",
    "        inplanes = new_block0.next_inplanes\n",
    "        inplanes_indices = new_block0.next_inplanes_indices\n",
    "        \n",
    "        layers.append(new_block0)\n",
    "        \n",
    "        \n",
    "        for i in range(1, blocks-1):\n",
    "            blocki = origin_layer[i]\n",
    "            new_blocki = PrunedBottleneck(blocki, inplanes, inplanes_indices, downsample=None)\n",
    "            inplanes = new_blocki.next_inplanes\n",
    "            inplanes_indices = new_blocki.next_inplanes_indices\n",
    "            layers.append(new_blocki)\n",
    "        \n",
    "\n",
    "        return nn.Sequential(*layers), inplanes, inplanes_indices\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        \n",
    "#         print('0: ',x.size())\n",
    "\n",
    "        x = self.layer1(x)\n",
    "#         print('1: ',x.size())\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "#         print('2: ',x.size())\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "#         print('3: ',x.size())\n",
    "        \n",
    "        x = self.layer4(x)\n",
    "#         print('4: ',x.size())\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cpu_model = model.cpu()\n",
    "# pruned_network = CloneResNet101(model)\n",
    "# pruned_network = pruned_network.cuda()\n",
    "# example = torch.rand(1, 3, 224, 224).cuda()\n",
    "# out = pruned_network(example)\n",
    "#print(pruned_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks:  3\n",
      "======\n",
      "layer1::\n",
      "Sequential(\n",
      "  (0): CloneBottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): CloneBottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): CloneBottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "---\n",
      "\n",
      "\n",
      "blocks:  4\n",
      "======\n",
      "layer2::\n",
      "Sequential(\n",
      "  (0): CloneBottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): CloneBottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): CloneBottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): CloneBottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "---\n",
      "\n",
      "\n",
      "blocks:  23\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "76 180\n",
      "======\n",
      "layer3::\n",
      "Sequential(\n",
      "  (0): PrunedBottleneck(\n",
      "    (conv1): Conv2d(512, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (6): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (7): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (8): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (9): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (10): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (11): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (12): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (13): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (14): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (15): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (16): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (17): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (18): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (19): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (20): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (21): PrunedBottleneck(\n",
      "    (conv1): Conv2d(1024, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(180, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "---\n",
      "\n",
      "\n",
      "blocks:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_layer4::\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "======\n",
      "layer4::\n",
      "Sequential(\n",
      "  (0): CloneBottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): CloneBottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): CloneBottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "---\n",
      "\n",
      "\n",
      "evaluate: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/782]\tTime 6.773 (6.773)\tLoss 0.6370 (0.6370)\tPrec@1 87.500 (87.500)\tPrec@5 95.312 (95.312)\n",
      "Test: [200/782]\tTime 0.229 (0.222)\tLoss 0.7767 (0.7203)\tPrec@1 84.375 (81.281)\tPrec@5 93.750 (95.421)\n",
      "Test: [400/782]\tTime 0.188 (0.207)\tLoss 0.7671 (0.8439)\tPrec@1 78.125 (78.581)\tPrec@5 95.312 (94.373)\n",
      "Test: [600/782]\tTime 0.189 (0.201)\tLoss 0.9634 (0.9555)\tPrec@1 84.375 (76.201)\tPrec@5 90.625 (92.993)\n",
      " * Prec@1 75.154 Prec@5 92.414 Error@1 24.846\n",
      "small model accu 75.154\n"
     ]
    }
   ],
   "source": [
    "pruned_network = CloneResNet101(model.cpu())\n",
    "small_model = torch.nn.DataParallel(pruned_network).cuda()\n",
    "print('evaluate: small')\n",
    "print('small model accu', validate(val_loader, small_model, criterion, log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CloneResNet101. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CloneBottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type PrunedBottleneck. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(small_model, 'pruned_layer3_resnet101_0.7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n",
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/782]\tTime 6.753 (6.753)\tLoss 0.6370 (0.6370)\tPrec@1 87.500 (87.500)\tPrec@5 95.312 (95.312)\n",
      "Test: [200/782]\tTime 0.233 (0.233)\tLoss 0.7767 (0.7203)\tPrec@1 84.375 (81.281)\tPrec@5 93.750 (95.421)\n",
      "Test: [400/782]\tTime 0.172 (0.216)\tLoss 0.7671 (0.8439)\tPrec@1 78.125 (78.581)\tPrec@5 95.312 (94.373)\n",
      "Test: [600/782]\tTime 0.173 (0.209)\tLoss 0.9634 (0.9555)\tPrec@1 84.375 (76.201)\tPrec@5 90.625 (92.993)\n"
     ]
    }
   ],
   "source": [
    "loaded_model = torch.load('pruned_layer3_resnet101_0.7.pth')\n",
    "small_load_model = loaded_model.cuda() #torch.nn.DataParallel(loaded_model).cuda()\n",
    "print('evaluate: small')\n",
    "print('small model accu', validate(val_loader, small_load_model, criterion, log, is_cuda=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lr = 0.1\n",
    "args.lr_adjust=30\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 1e-4\n",
    "args.print_freq = 200\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // args.lr_adjust))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, log):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        #input = input.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print_log('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses, top1=top1, top5=top5), log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    \n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=256, shuffle=True,\n",
    "    num_workers=8, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/5005]\tTime 17.759 (17.759)\tData 13.745 (13.745)\tLoss 1.3956 (1.3956)\tPrec@1 65.625 (65.625)\tPrec@5 87.500 (87.500)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-23f27ce84eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mval_acc_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4dd1d596dc36>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, log)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtop5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay,\n",
    "                            nesterov=True)\n",
    "\n",
    "\n",
    "# val_acc_1 = validate(val_loader, small_model, criterion, log)\n",
    "\n",
    "# print(\">>>>> accu before is: {:}\".format(val_acc_1))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "epoch_time = AverageMeter()\n",
    "\n",
    "epoches = 2\n",
    "best_prec1 = 0\n",
    "\n",
    "for epoch in range(0, epoches):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, small_model, criterion, optimizer, epoch, log)\n",
    "    # evaluate on validation set\n",
    "    val_acc_1 = validate(val_loader, small_model, criterion, log)\n",
    "\n",
    "    \n",
    "    epoch_time.update(time.time() - start_time)\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 31.72 GiB total capacity; 30.24 GiB already allocated; 27.88 MiB free; 30.71 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-94bd23afbd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate: small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'small model accu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7350b0b62c3c>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(val_loader, model, criterion, log)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mdc/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c2cfde722dc7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;31m#         print('2: ',x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;31m#         print('3: ',x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mdc/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mdc/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mdc/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-8059e22fd081>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m#print('block-0:', x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mdc/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mdc/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mdc/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 31.72 GiB total capacity; 30.24 GiB already allocated; 27.88 MiB free; 30.71 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "print('evaluate: small')\n",
    "print('small model accu', validate(val_loader, small_model, criterion, log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1832,  0.4630,  0.3385,  ..., -0.2549, -0.3382, -0.7052],\n",
      "          [-0.2600, -0.3938, -0.5602,  ...,  0.4342,  0.0499,  0.6193],\n",
      "          [ 0.1438, -0.0319, -0.2912,  ..., -0.9251, -0.2181, -0.3713],\n",
      "          ...,\n",
      "          [ 0.3281, -0.8527, -1.1207,  ..., -0.6123, -0.2748,  0.0983],\n",
      "          [-0.3462,  0.2096,  1.0418,  ..., -0.2365,  0.8906,  0.8099],\n",
      "          [-0.2473, -0.2383, -0.3965,  ...,  0.3147, -0.6539, -0.7158]],\n",
      "\n",
      "         [[-0.5738,  0.0835,  2.3208,  ...,  0.2214,  0.6061,  0.4176],\n",
      "          [ 0.3679, -0.0086, -1.8610,  ...,  0.2497, -0.2142,  0.4031],\n",
      "          [ 0.0830,  0.2935,  0.4378,  ...,  0.1226, -0.9952,  0.8878],\n",
      "          ...,\n",
      "          [ 0.4524, -0.6929, -0.4924,  ...,  0.4848,  0.0381, -0.3537],\n",
      "          [-0.4654,  0.1049,  0.0948,  ..., -0.3540,  0.0705,  0.2736],\n",
      "          [ 0.6062, -0.1947,  0.9414,  ...,  0.6538,  0.7172, -0.0060]],\n",
      "\n",
      "         [[-0.9819, -0.4133, -0.0793,  ..., -0.8533,  0.2454, -1.2887],\n",
      "          [-2.0572, -0.2565,  0.3281,  ..., -0.7541,  0.2849, -1.6937],\n",
      "          [-2.3215,  0.0650,  0.3379,  ...,  0.1837, -0.1880, -1.6046],\n",
      "          ...,\n",
      "          [-0.7638, -0.2851, -0.4447,  ..., -0.5967, -0.3979, -1.1106],\n",
      "          [-0.4628, -0.9032,  0.1212,  ..., -0.3838, -0.3237, -1.3885],\n",
      "          [-1.1303, -0.2408,  0.2261,  ..., -0.3227, -0.1738, -1.1491]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1351,  1.7413,  1.4511,  ...,  2.0525,  2.1015,  0.9866],\n",
      "          [ 2.1324,  1.6193,  1.3791,  ...,  1.6564,  1.6074,  0.7393],\n",
      "          [ 1.7371,  1.8547,  1.5873,  ...,  1.6804,  1.5433,  0.5498],\n",
      "          ...,\n",
      "          [ 1.5773,  1.8391,  1.4718,  ...,  1.8417,  1.9817,  1.2607],\n",
      "          [ 1.3256,  1.2806,  1.2914,  ...,  1.1245,  1.1941,  0.8069],\n",
      "          [ 1.3852,  1.2538,  1.3191,  ...,  1.1101,  1.0748,  0.6723]],\n",
      "\n",
      "         [[ 0.0348, -0.3020, -1.6960,  ..., -0.5907, -0.5578, -0.5687],\n",
      "          [-0.4171, -0.7223,  1.5789,  ..., -0.0424,  0.0095, -0.1605],\n",
      "          [-0.1962, -0.3520, -0.6816,  ..., -0.0492, -0.0399, -0.3932],\n",
      "          ...,\n",
      "          [-0.4043, -0.0560, -0.2119,  ..., -0.2536, -0.5448, -0.1809],\n",
      "          [ 0.6950,  0.0225, -0.4021,  ...,  0.5041,  0.2749, -0.5873],\n",
      "          [-0.9686,  0.0207, -0.8382,  ..., -1.0907, -0.7019, -0.2488]],\n",
      "\n",
      "         [[ 1.1113,  1.2160,  1.1013,  ...,  0.8222,  0.8059,  0.9835],\n",
      "          [ 1.3480,  1.3077,  1.1119,  ...,  0.8924,  0.9179,  0.8756],\n",
      "          [ 1.4067,  1.2552,  1.2429,  ...,  0.9663,  1.1651,  1.1351],\n",
      "          ...,\n",
      "          [ 1.1767,  1.5834,  1.5920,  ...,  1.3336,  0.8646,  0.5830],\n",
      "          [ 1.3854,  1.3877,  1.6121,  ...,  1.7034,  1.3225,  0.7033],\n",
      "          [ 0.6421,  0.4556,  0.7280,  ...,  1.3086,  1.3439,  0.7815]]]],\n",
      "       grad_fn=<MkldnnConvolutionBackward>)\n",
      "\n",
      "\n",
      "\n",
      "tensor([[[[ 0.1832,  0.4630,  0.3385,  ..., -0.2549, -0.3382, -0.7052],\n",
      "          [-0.2600, -0.3938, -0.5602,  ...,  0.4342,  0.0499,  0.6193],\n",
      "          [ 0.1438, -0.0319, -0.2912,  ..., -0.9251, -0.2181, -0.3713],\n",
      "          ...,\n",
      "          [ 0.3281, -0.8527, -1.1207,  ..., -0.6123, -0.2748,  0.0983],\n",
      "          [-0.3462,  0.2096,  1.0418,  ..., -0.2365,  0.8906,  0.8099],\n",
      "          [-0.2473, -0.2383, -0.3965,  ...,  0.3147, -0.6539, -0.7158]],\n",
      "\n",
      "         [[-0.5738,  0.0835,  2.3208,  ...,  0.2214,  0.6061,  0.4176],\n",
      "          [ 0.3679, -0.0086, -1.8610,  ...,  0.2497, -0.2142,  0.4031],\n",
      "          [ 0.0830,  0.2935,  0.4378,  ...,  0.1226, -0.9952,  0.8878],\n",
      "          ...,\n",
      "          [ 0.4524, -0.6929, -0.4924,  ...,  0.4848,  0.0381, -0.3537],\n",
      "          [-0.4654,  0.1049,  0.0948,  ..., -0.3540,  0.0705,  0.2736],\n",
      "          [ 0.6062, -0.1947,  0.9414,  ...,  0.6538,  0.7172, -0.0060]],\n",
      "\n",
      "         [[-0.9819, -0.4133, -0.0793,  ..., -0.8533,  0.2454, -1.2887],\n",
      "          [-2.0572, -0.2565,  0.3281,  ..., -0.7541,  0.2849, -1.6937],\n",
      "          [-2.3215,  0.0650,  0.3379,  ...,  0.1837, -0.1880, -1.6046],\n",
      "          ...,\n",
      "          [-0.7638, -0.2851, -0.4447,  ..., -0.5967, -0.3979, -1.1106],\n",
      "          [-0.4628, -0.9032,  0.1212,  ..., -0.3838, -0.3237, -1.3885],\n",
      "          [-1.1303, -0.2408,  0.2261,  ..., -0.3227, -0.1738, -1.1491]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0348, -0.3020, -1.6960,  ..., -0.5907, -0.5578, -0.5687],\n",
      "          [-0.4171, -0.7223,  1.5789,  ..., -0.0424,  0.0095, -0.1605],\n",
      "          [-0.1962, -0.3520, -0.6816,  ..., -0.0492, -0.0399, -0.3932],\n",
      "          ...,\n",
      "          [-0.4043, -0.0560, -0.2119,  ..., -0.2536, -0.5448, -0.1809],\n",
      "          [ 0.6950,  0.0225, -0.4021,  ...,  0.5041,  0.2749, -0.5873],\n",
      "          [-0.9686,  0.0207, -0.8382,  ..., -1.0907, -0.7019, -0.2488]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 1.1113,  1.2160,  1.1013,  ...,  0.8222,  0.8059,  0.9835],\n",
      "          [ 1.3480,  1.3077,  1.1119,  ...,  0.8924,  0.9179,  0.8756],\n",
      "          [ 1.4067,  1.2552,  1.2429,  ...,  0.9663,  1.1651,  1.1351],\n",
      "          ...,\n",
      "          [ 1.1767,  1.5834,  1.5920,  ...,  1.3336,  0.8646,  0.5830],\n",
      "          [ 1.3854,  1.3877,  1.6121,  ...,  1.7034,  1.3225,  0.7033],\n",
      "          [ 0.6421,  0.4556,  0.7280,  ...,  1.3086,  1.3439,  0.7815]]]],\n",
      "       grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "cpu_pruned = pruned_network.cpu()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#out = cpu_pruned.forward(example)\n",
    "\n",
    "\n",
    "cpu_model = model.cpu()\n",
    "\n",
    "\n",
    "x1 = cpu_pruned.conv1(example)\n",
    "\n",
    "x2 = cpu_model.conv1(example)\n",
    "\n",
    "print(x1)\n",
    "\n",
    "print('\\n\\n')\n",
    "print(x2)\n",
    "\n",
    "\n",
    "# print(x1-x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate: small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/hongky/.conda/envs/mdc/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/782]\tTime 1.752 (1.752)\tLoss 0.4534 (0.4534)\tPrec@1 93.750 (93.750)\tPrec@5 95.312 (95.312)\n",
      "Test: [200/782]\tTime 0.099 (0.109)\tLoss 0.6202 (0.6282)\tPrec@1 85.938 (83.629)\tPrec@5 93.750 (96.494)\n",
      "Test: [400/782]\tTime 0.100 (0.105)\tLoss 0.3566 (0.7328)\tPrec@1 92.188 (81.312)\tPrec@5 98.438 (95.577)\n",
      "Test: [600/782]\tTime 0.101 (0.103)\tLoss 0.6925 (0.8386)\tPrec@1 87.500 (79.149)\tPrec@5 96.875 (94.374)\n",
      " * Prec@1 78.220 Prec@5 93.968 Error@1 21.780\n",
      "small model accu 78.22\n"
     ]
    }
   ],
   "source": [
    "big_model = model.cuda()\n",
    "print('evaluate: small')\n",
    "print('small model accu', validate(val_loader, big_model, criterion, log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-24019f7c1b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbig_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbig_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "big_model.conv1.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches-99 :: 0.9-keep :: acc 78.22\n",
    "epoches-99 :: 0.7-keep :: acc 77.684\n",
    "epoches-55 :: 0.6-keep :: acc 72.430\n",
    "epoches-51 :: 0.5-keep :: acc 60.704\n",
    "epoches-33 :: 0.4-keep :: acc 17.450"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdc",
   "language": "python",
   "name": "mdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
